<!doctype html><html lang=en-us dir=ltr data-wc-theme-default=system><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 0.3.1"><meta name=author content="Naomi Saphra"><meta name=description content="I discuss what counts as strong evidence for an explanation of model behavior."><link rel=alternate hreflang=en-us href=https://nsaphra.net/post/prinia/><link rel=stylesheet href=/css/themes/emerald.min.css><link href=/dist/wc.min.css rel=stylesheet><script>window.hbb={defaultTheme:document.documentElement.dataset.wcThemeDefault,setDarkTheme:()=>{document.documentElement.classList.add("dark"),document.documentElement.style.colorScheme="dark"},setLightTheme:()=>{document.documentElement.classList.remove("dark"),document.documentElement.style.colorScheme="light"}},console.debug(`Default Hugo Blox Builder theme is ${window.hbb.defaultTheme}`),"wc-color-theme"in localStorage?localStorage.getItem("wc-color-theme")==="dark"?window.hbb.setDarkTheme():window.hbb.setLightTheme():(window.hbb.defaultTheme==="dark"?window.hbb.setDarkTheme():window.hbb.setLightTheme(),window.hbb.defaultTheme==="system"&&(window.matchMedia("(prefers-color-scheme: dark)").matches?window.hbb.setDarkTheme():window.hbb.setLightTheme()))</script><script>document.addEventListener("DOMContentLoaded",function(){let e=document.querySelectorAll("li input[type='checkbox'][disabled]");e.forEach(e=>{e.parentElement.parentElement.classList.add("task-list")});const t=document.querySelectorAll(".task-list li");t.forEach(e=>{let t=Array.from(e.childNodes).filter(e=>e.nodeType===3&&e.textContent.trim().length>1);if(t.length>0){const n=document.createElement("label");t[0].after(n),n.appendChild(e.querySelector("input[type='checkbox']")),n.appendChild(t[0])}})})</script><link rel=icon type=image/png href=/media/icon_hu_4d36134051bb7026.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu_d9b2d55b74fabcc9.png><link rel=canonical href=https://nsaphra.net/post/prinia/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@nsaphra"><meta property="twitter:creator" content="@nsaphra"><meta property="og:site_name" content="Naomi Saphra"><meta property="og:url" content="https://nsaphra.net/post/prinia/"><meta property="og:title" content="The Parable of the Prinia's Egg: An Allegory for AI Science | Naomi Saphra"><meta property="og:description" content="I discuss what counts as strong evidence for an explanation of model behavior."><meta property="og:image" content="https://nsaphra.net/media/icon_hu_ecc3d54b494abbac.png"><meta property="twitter:image" content="https://nsaphra.net/media/icon_hu_ecc3d54b494abbac.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-09-17T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-17T00:00:00+00:00"><title>The Parable of the Prinia's Egg: An Allegory for AI Science | Naomi Saphra</title><style>@font-face{font-family:inter var;font-style:normal;font-weight:100 900;font-display:swap;src:url(/dist/font/Inter.var.woff2)format(woff2)}</style><link type=text/css rel=stylesheet href=/dist/pagefind/pagefind-ui.be766eb419317a14ec769d216e9779bfe8f3737c80e780f4ba0dafb57a41a482.css integrity="sha256-vnZutBkxehTsdp0hbpd5v+jzc3yA54D0ug2vtXpBpII="><script src=/dist/pagefind/pagefind-ui.87693d7c6f2b3b347ce359d0ede762c033419f0a32b22ce508c335a81d841f1b.js integrity="sha256-h2k9fG8rOzR841nQ7ediwDNBnwoysizlCMM1qB2EHxs="></script><script>window.hbb.pagefind={baseUrl:"/"}</script><style>html.dark{--pagefind-ui-primary:#eeeeee;--pagefind-ui-text:#eeeeee;--pagefind-ui-background:#152028;--pagefind-ui-border:#152028;--pagefind-ui-tag:#152028}</style><script>window.addEventListener("DOMContentLoaded",e=>{new PagefindUI({element:"#search",showSubResults:!0,baseUrl:window.hbb.pagefind.baseUrl,bundlePath:window.hbb.pagefind.baseUrl+"pagefind/"})}),document.addEventListener("DOMContentLoaded",()=>{let e=document.getElementById("search"),t=document.getElementById("search_toggle");t&&t.addEventListener("click",()=>{if(e.classList.toggle("hidden"),e.querySelector("input").value="",e.querySelector("input").focus(),!e.classList.contains("hidden")){let t=document.querySelector(".pagefind-ui__search-clear");t&&!t.hasAttribute("listenerOnClick")&&(t.setAttribute("listenerOnClick","true"),t.addEventListener("click",()=>{e.classList.toggle("hidden")}))}})})</script><link type=text/css rel=stylesheet href=/dist/lib/katex/katex.min.505d5f829022bb7b4f24dfee0aa1141cd7bba67afe411d1240335f820960b5c3.css integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM="><script defer src=/dist/lib/katex/katex.min.dc84b296ec3e884de093158f760fd9d45b6c7abe58b5381557f4e138f46a58ae.js integrity="sha256-3ISyluw+iE3gkxWPdg/Z1Ftser5YtTgVV/ThOPRqWK4="></script><script defer src=/js/katex-renderer.6579ec9683211cfb952064aedf3a3baea5eeb17a061775b32b70917474637c80.js integrity="sha256-ZXnsloMhHPuVIGSu3zo7rqXusXoGF3WzK3CRdHRjfIA="></script><script defer src=/js/hugo-blox-en.min.8c8ea06bd0420f5067e52fa727b9f92303757322ba4431774153d59a9735eadb.js integrity="sha256-jI6ga9BCD1Bn5S+nJ7n5IwN1cyK6RDF3QVPVmpc16ts="></script><script async defer src=https://buttons.github.io/buttons.js></script></head><body class="dark:bg-hb-dark dark:text-white page-wrapper" id=top><div id=page-bg></div><div class="page-header sticky top-0 z-30"><header id=site-header class=header><nav class="navbar px-3 flex justify-left"><div class="order-0 h-100"><a class=navbar-brand href=/ title="Naomi Saphra">Naomi Saphra</a></div><input id=nav-toggle type=checkbox class=hidden>
<label for=nav-toggle class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1"><svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20"><title>Open Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0V0z"/></svg><svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20"><title>Close Menu</title><polygon points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2" transform="rotate(45 10 10)"/></svg></label><ul id=nav-menu class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8 justify-left"><li class=nav-item><a class=nav-link href=/>Bio</a></li><li class=nav-item><a class=nav-link href=/#posts>Posts</a></li><li class=nav-item><a class=nav-link href=/#papers>Publications</a></li></ul><div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0"><button aria-label=search class="text-black hover:text-primary inline-block px-3 text-xl dark:text-white" id=search_toggle><svg height="16" width="16" viewBox="0 0 512 512" fill="currentcolor"><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8.0 45.3s-32.8 12.5-45.3.0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9.0 208S93.1.0 208 0 416 93.1 416 208zM208 352a144 144 0 100-288 144 144 0 100 288z"/></svg></button><div class="px-3 text-black hover:text-primary-700 dark:text-white dark:hover:text-primary-300
[&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white"><button class="theme-toggle mt-1" accesskey=t title=appearance><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="dark:hidden"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="dark:block [&:not(dark)]:hidden"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div></nav></header><div id=search class="hidden p-3"></div></div><div class="page-body my-10"><div class="mx-auto flex max-w-screen-xl"><aside class="hb-sidebar-container max-lg:[transform:translate3d(0,-100%,0)] lg:hidden xl:block"><div class="px-4 pt-4 lg:hidden"></div><div class="hb-scrollbar lg:h-[calc(100vh-var(--navbar-height))]"><ul class="flex flex-col gap-1 lg:hidden"><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/event/>Recent & Upcoming Talks
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/event/example/>Example Talk</a></li></ul></div></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/>Publications
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/hublog/>How to visualize training dynamics in neural networks</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/polypythias/>PolyPythias: Stability and Outliers across Fifty Language Model Pre-Training Runs</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/prashanth-2024-recitereconstructrecollectmemorization/>Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/systematicity/>Attribute Diversity Determines the Systematicity Gap in VQA</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/bench/>Benchmarks as Microscopes: A Call for Model Metrology</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/jenny/>Causation Does Not Imply Correlation: A Study of Circuit Mechanisms and Model Behaviors</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/li-2024-chatgptdoesnttrustchargers/>ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/rosie/>Distributional Scaling Laws for Emergent Capabilities</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/ankner/>Dynamic Masking Rate Schedules for MLM Pretraining</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/ff/>Fast Forwarding Low-Rank Training</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/parse/>First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sara-loss/>Loss in the Crowd: Hidden Breakthroughs in Language Model Training</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sarah-mech/>Mechanistic?</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sunny/>Sometimes I am a Tree: Data drives fragile hierarchical generalization</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/chen/>Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sherborne-tram-2023/>TRAM: Bridging Trust Regions and Sharpness Aware Minimization</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/zhang-2024-transcendence/>Transcendence: Generative Models Can Outperform The Experts That Train Them</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/johnson-yu-2024-understanding/>Understanding biological active sensing behaviors by interpreting learned artificial agent policies</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/hu/>Delays, Detours, and Forks in the Road: Latent State Models of Training Dynamics</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/saphra-2023-interp/>Interpretability Creationism</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/juneja-linear-2023/>Linear Connectivity Reveals Generalization Strategies</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/attrib/>Shapley Interactions for Complex Feature Attribution</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/hupkes-state-art-2023/>State-of-the-art generalisation research in NLP: a taxonomy and review</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sultan/>Towards out-of-distribution generalization in large-scale astronomical surveys: robust networks learn similar representations</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/valvoda-learning-2022/>Learning Transductions to Test Systematic Compositionality</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/zhao-one-2022/>One Venue, Two Conferences: The Separation of Chinese and American Citation Networks</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sellam-multiberts-2021/>The MultiBERTs: BERT Reproductions for Robustness Analysis</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/white-nonlinear-2020/>A Non-Linear Structural Probe</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/saphra-lstms-2020/>LSTMs Compose---and Learn---Bottom-Up</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/pimentel-pareto-2020/>Pareto Probing: Trading Off Accuracy for Complexity</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/tahaei/>Understanding Privacy-Related Questions on Stack Overflow</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/kate/>Carbon AI and the Concentration of Computational Work</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/saphra-sparsity/>Sparsity Emerges Naturally in Neural Language Models</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/saphra-understand-2019/>Understanding Learning Dynamics Of Language Models with SVCCA</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/dynet/>DyNet: The Dynamic Neural Network Toolkit</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/pos-first/>Evaluating Informal-Domain Word Representations with UrbanDictionary</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/naomi-saphra-amrica-2015/>AMRICA: an AMR Inspector for Cross-language Alignments</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/schneider-framework-2014/>A framework for (under) specifying dependency syntax without overloading annotators</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/cotterell-algerian-2014/>An Algerian Arabic-French Code-Switched Corpus</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/vedaldi-understanding-2014/>Understanding Objects in Detail with Fine-grained Attributes</a></li></ul></div></li><li class=open><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/>Blog
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col open"><a class="hb-sidebar-custom-link
sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900" href=/post/prinia/>The Parable of the Prinia's Egg: An Allegory for AI Science</a><ul class=hb-sidebar-mobile-toc><li><a href=#instance-level-interpretability class=hb-docs-link>Instance level interpretability</a></li><li><a href=#epistemology-and-evidence class=hb-docs-link>Epistemology and evidence</a></li><li><a href=#whats-the-evidence-for-syntactic-attention-structure class=hb-docs-link>What&amp;rsquo;s the evidence for Syntactic Attention Structure?</a></li><li><a href=#conclusion class=hb-docs-link>Conclusion</a></li></ul></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/creationism/>Interpretability Creationism</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/monodomainism/>Against Monodomainism</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/hands/>What Does a Coder Do If They Can't Type?</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/model-scheduling/>Model Scheduling</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/lda/>Understanding Latent Dirichlet Allocation</a></li></ul></div></li></ul><div class="max-xl:hidden h-0 w-64 shrink-0"></div></div></aside><nav class="hb-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents"><div class="hb-scrollbar text-sm [hyphens:auto] sticky top-16 overflow-y-auto pr-4 pt-6 max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] -mr-4 rtl:-ml-4"><p class="mb-4 font-semibold tracking-tight">On this page</p><ul><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#instance-level-interpretability>Instance level interpretability</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#syntactic-attention-structure>Syntactic Attention Structure</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#when-does-instance-level-analysis-fail>When does instance-level analysis fail?</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#epistemology-and-evidence>Epistemology and evidence</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#cracking-the-case-of-the-cuckoo-culprit>Cracking the case of the cuckoo culprit</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#whats-the-evidence-for-syntactic-attention-structure>What’s the evidence for Syntactic Attention Structure?</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#atemporal-correlational>Atemporal correlational</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#developmental-observational>Developmental observational</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#developmental-causal>Developmental causal</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#conclusion>Conclusion</a></li></ul>
    
    
  </div></nav><article class="w-full break-words flex min-h-[calc(100vh-var(--navbar-height))] min-w-0 justify-center pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]"><main class="w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12"><h1 class="mt-2 text-4xl font-bold tracking-tight text-slate-900 dark:text-slate-100">The Parable of the Prinia's Egg: An Allegory for AI Science</h1><div class="mt-4 mb-16"><div class="text-gray-500 dark:text-gray-300 text-sm flex items-center flex-wrap gap-y-2"><span class=mr-1>Sep 17, 2023</span><span class=mx-1>·</span><div class="group inline-flex items-center text-current gap-x-1.5 mx-1"><img src=/author/naomi-saphra/avatar_hu_173659a9cfad1518.webp alt="Naomi Saphra" class="inline-block h-4 w-4 rounded-full border border-current" loading=lazy><div>Naomi Saphra</div></div><span class=mx-1>·</span>
<span class=mx-1>10 min read</span></div><div class=mt-3></div></div><div class="prose prose-slate lg:prose-xl dark:prose-invert"><p><figure><div class="flex justify-center"><div class=w-100><img src=/images/eggs.jpg alt="Prinia eggs" loading=lazy data-zoomable></div></div></figure></p><p>When European scientists first encountered the eggs of the tawny-flanked prinia <em>Prinia subflava</em>, an African nesting bird, they believed they understood what they had found. The prinia lay eggs that exhibited swirls, speckles, and coloration unique to each individual bird. What purpose do such patterns serve in nature? Surely, scientists agreed, these markings allowed the eggs to camouflage and blend into the nest.</p><p>One 19th century naturalist, Charles Francis Massey Swynnerton, offered an alternative explanation. Why would each bird have its own unique patterns? Swynnerton believed that the markings functioned as watermarks, allowing the nesting bird to differentiate its own eggs from those of the cuckoo finch <em>Anomalospiza imberbis</em>. The cuckoo finch is an <strong>obligate brood parasite</strong>, meaning that it does not build its own nest, but instead lays its eggs in the nests of other birds, particularly the prinia.</p><p>Since its proposal, evidence for Swynnerton&rsquo;s hypothesis has accumulated. The camouflage hypothesis was based on anecdotal observations of eggs, without correlational or experimental data. In contrast, evidence for the brood parasite hypothesis comes in diverse forms, using many different frameworks for reasoning about causality and explanation, adding up to an indisputable scientific arsenal. What can AI researchers learn from the mature science of biology to strengthen our own evidence and reliably interpret how neural network traits contribute to model behavior?</p><h2 id=instance-level-interpretability>Instance level interpretability</h2><p>Most interpretability work, and much work in science of deep learning, relies on passive observations of phenomena with post-hoc explanations for how artifacts in the model contribute to model outputs. Like the early ornithologists suggesting that prinia eggs were camouflaged, interpretability researchers often identify some phenomenon and link it to model decisions based solely on their intuitions. Some work attempts a more principled approach, by intervening on the trained model to demonstrate that a given feature or circuit has a predictable effect on model judgment. Both approaches might be classed as <strong>instance-level</strong>, as they consider the behavior of a fully trained model on a given input sample.</p><p>In the past, I have called this reliance on fully trained models <a href=https://thegradient.pub/interpretability-creationism/ target=_blank rel=noopener>Interpretability Creationism</a>, and suggested that interpretability researchers instead measure the indicators they focus on throughout training. However, I have not detailed how these creationist approaches can lead us astray, nor have I proposed a clear framework for understanding development. Such a framework falls under the philosophical field of <strong>epistemology</strong>, the study of what makes a belief justified.</p><h3 id=syntactic-attention-structure>Syntactic Attention Structure</h3><p>To address the epistemology of interpretability, let us construct a case study of the scientific literature on an observed phenomenon in neural networks. One well-documented and intuitive behavior is how Transformer-based <strong>masked language models</strong> (MLMs) have specialized attention heads that focus on a specific dependency relation, a trait we will call <strong>Syntactic Attention Structure</strong> (SAS). We can illustrate SAS with an example sentence.</p><p><figure><div class="flex justify-center"><div class=w-100><img src=/images/parse_example.png alt="My bird builds ugly nests" loading=lazy data-zoomable></div></div></figure></p><p>In the preceding sentence, the model might be called upon to predict the masked-out target word <em>builds</em>. During inference, its specialized <code>nsubj</code> head will place its highest weight on <em>bird</em>, while its specialized <code>dobj</code> head will place its highest weight on <em>nests</em>. This specialization behavior emerges naturally, without any explicit inductive bias, over the normal course of training for models like BERT.</p><p>SAS was discovered concurrently in two papers. First, <a href=https://aclanthology.org/W19-4828/ target=_blank rel=noopener>Clark et al. (2019)</a> observed that specialized attention heads provide an implicit parse, which aligns with prior notions of dependency syntax, as measured by <strong>Unlabeled Attachment Score</strong> (UAS). This observation provides instance-level observational evidence for the role of SAS in masked language modeling. Second, <a href=https://aclanthology.org/P19-1580/ target=_blank rel=noopener>Voita et al. (2019)</a> discovered that pruning specialized syntactic heads damaged model performance more than pruning other heads, providing instance-level causal evidence for the role of SAS. What&rsquo;s missing from these studies, from an epistemological standpoint?</p><h3 id=when-does-instance-level-analysis-fail>When does instance-level analysis fail?</h3><p>There is an assumption underlying claims in interpretability: that the observed phenomenon measured by the interpretable <strong>indicator</strong> metric, such as implicit parse UAS, plays a role in determining some <strong>target</strong> metric, such as MLM validation loss or grammatical capabilities. However, instance-level evidence like the prior work on SAS might not support this assumption.</p><p>First, instance-level <em>observational</em> evidence might highlight artifacts that arose as a side effect of training, rather than as a crucial element in model decisions. That is, the poorly-understood dynamics of training might lead to structures emerging that are not required at test time. In evolutionary biology, such artifacts are called <a href=https://en.wikipedia.org/wiki/Spandrel_%28biology%29 target=_blank rel=noopener>spandrels</a>; proposed examples include human chins and musicality.</p><p>Second, instance-level <em>causal</em> evidence may be stronger, but remains flawed as evidence for the effect of SAS. For example, what if SAS emerges early in training, and gradually the model develops a more complex representation that does not rely on SAS, but the specialized heads have already become entangled with the rest of the high dimensional representation space? Then these specialized heads are <a href=https://en.wikipedia.org/wiki/Vestigiality target=_blank rel=noopener>vestigial</a>, like a human tailbone, but are integrated into distributed subnetworks that generate and cancel noise, so the network may be particularly brittle to their removal. Another weakness of instance-level causal interpretation is that it may claim that a given behavior is unimportant, when in fact the model relied on that trait to converge on its final solution, as webbing evolves for gliding before an organism can develop wings.</p><h2 id=epistemology-and-evidence>Epistemology and evidence</h2><p>As we see in the example of SAS, treating a model <strong>atemporally</strong>, in a manner detached from its development, might yield intriguing phenomena and even suggest insights. However, in order to strengthen the evidence for these insights, we argue for applying <strong>developmental</strong> analysis. Developmental history may shed more light on the effect of a given indicator on a target metric, compared to atemporal data.</p><p>Beyond the question of whether we have access to development data, there are three widely used categories of evidence in the scientific literature. Any one of the following categories might apply in either atemporal or developmental settings.</p><ul><li><strong>Observational</strong>: For example, <em>BERT exhibits SAS and also demonstrates grammatical capabilities</em>. This is evidence based on passive observation of a given phenomenon. Atemporal observations are not strong evidence of a relationship between that phenomenon and the target of analysis, like a generalization metric. However, observations of development may support a relationship between the indicator and target metrics.</li><li><strong>Correlational</strong>: For example, <em>SAS is correlated with grammatical capabilities across a population of multiple models</em>. This is evidence based on natural variation of a given phenomenon.</li><li><strong>Causal</strong>: For example, <em>grammatical capabilities are affected by intervening on SAS</em>. This is evidence based on experimental interventions on the indicator phenomenon.</li></ul><h3 id=cracking-the-case-of-the-cuckoo-culprit>Cracking the case of the cuckoo culprit</h3><p>Returning to the example of the prinia, the assumption that their egg markings served as camouflage was based on atemporal observational evidence. Brood parasites (the indicator) do, in fact, drive the evolution of egg markings (the target of analysis). There are several epistemically strong pieces of evidence that ornithologists have found for that influence, including:</p><ul><li><strong>Atemporal correlational</strong>: A brood parasite&rsquo;s favored hosts, like the prinia, have more individualized markings than other nesting birds.</li><li><strong>Developmental observational</strong>: On continents with a longer evolutionary history of brood parasitism, such as Africa and Australia, nesting birds have more elaborate egg patterns compared to Europe, which has a shorter history of parasitism, or North America, which has no obligate brood parasites at all. If we treat each continent as though we are observing a checkpoint at some point in the evolutionary arms race between parasite and host, we can see that egg markings appear to be dependent on brood parasitism during evolutionary development.</li><li><strong>Developmental causal</strong>: Invasive species of nesting birds provide a natural experiment for testing the link between brood parasitism and egg markings. When a host species spreads from its native range to an island without brood parasites, Australian ornithologists have observed that the species gradually loses its intricate egg markings over subsequent generations.</li></ul><h2 id=whats-the-evidence-for-syntactic-attention-structure>What&rsquo;s the evidence for Syntactic Attention Structure?</h2><p>Does SAS play a significant role in the capabilities of a masked language model? In our latest paper, <a href=https://arxiv.org/abs/2309.07311 target=_blank rel=noopener>Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs</a>, we test the impact of SAS by mirroring the variety of evidence collected by ornithologists. Let&rsquo;s walk through the relevant results.</p><h3 id=atemporal-correlational>Atemporal correlational</h3><p>Correlational evidence is stronger when the variation in a population is known to be random, other than the metrics in focus, because this scenario allows us to control for the effect of confounding factors. This is the reason why, for example, genetics studies that use adopted children are stronger than those that study children raised by their biological parents, thereby confounding nature and nurture. Fortunately, deep learning allows us to generate random variation across models easily, by varying the training seed.</p><p><figure><div class="flex justify-center"><div class=w-100><img src=/images/corr_plots.png alt="Correlation scatterplots." loading=lazy data-zoomable></div></div></figure></p><p>Unfortunately, the correlational results above seem to be bleak for the idea that SAS is crucial to model capabilities. Using 25 independently trained MLMs from <a href=https://arxiv.org/abs/2106.16163 target=_blank rel=noopener>MultiBERTs</a>, we see no significant correlation, or even a clear pattern, between UAS (our SAS metric) and either validation loss or linguistic capabilities (in the form of <a href=https://aclanthology.org/2020.tacl-1.25/ target=_blank rel=noopener>BLiMP score</a>).</p><p>Should we abandon SAS as a phenomenon unrelated to performance in practice? Not so fast. It may be that random variation does not elicit strong enough differences in SAS to register a behavioral difference. In order to dig deeper, we now turn to using a developmental lens by considering the training process.</p><h3 id=developmental-observational>Developmental observational</h3><p><figure><div class="flex justify-center"><div class=w-100><img src=/images/development_plots.png alt="BERT training." loading=lazy data-zoomable></div></div></figure></p><p>Next, we passively observe SAS in an MLM model (a retrained BERT_base run with 3 different random seeds), but consider it during the entire course of training rather than at a single checkpoint. Results here appear to be far more promising, thanks to the clarity of an abrupt breakthrough in UAS about 20K steps into training. First, we see that there is a precipitous drop in loss coinciding with this UAS spike (marked ▲). Then, after UAS reaches its peak and begins to plateau, we observe an immediate jump in the MLM&rsquo;s particular linguistic capabilities, as measured by BLiMP (marked ⏺). It certainly appears that the former is dependent on the latter. While we can directly observe that internal SAS structure precedes the acquisition of linguistic capabilities, though, can we guarantee that SAS <em>precipitates</em> linguistic capabilities?</p><h3 id=developmental-causal>Developmental causal</h3><p><figure><div class="flex justify-center"><div class=w-100><img src=/images/causal_plots.png alt="Bert training with causal interventions." loading=lazy data-zoomable></div></div></figure></p><p>To study how connected these consecutive phase transitions are, we intervene on the training process to suppress and promote SAS, yielding models respectively called BERT_SAS- and BERT_SAS+. Although neither promoting nor suppressing helps long term MLM performance, observing the training process shows clear evidence of a dependency. Promoting SAS leads to an earlier UAS spike, which indeed precipitates an earlier spike in linguistic capabilities. Meanwhile, suppressing SAS prevents any UAS spike and leads to persistently poor linguistic capabilities throughout training.</p><h2 id=conclusion>Conclusion</h2><p>By monitoring MLM training, we have found epistemically strong evidence of a connection between SAS and model performance, in particular through linguistic capabilities. These results are described in a new paper led by <a href=https://angie-chen55.github.io/ target=_blank rel=noopener>Angelica Chen</a> working with <a href=https://www.ravid-shwartz-ziv.com/ target=_blank rel=noopener>Ravid Schwartz-Ziv</a>, <a href=https://kyunghyuncho.me/ target=_blank rel=noopener>Kyunghyun Cho</a>, <a href=https://mleavitt.net/ target=_blank rel=noopener>Matthew Leavitt</a>, and me: <a href=https://arxiv.org/abs/2309.07311 target=_blank rel=noopener>Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs</a>.</p><p>Beyond the results obtained through our approach to interpretability epistemology, this paper also presents a large number of related findings. The full paper is worth reading, I think, as the results described here might not even be the most interesting part! We link these interpretable training dynamics to the broader literature on simplicity bias, model complexity, and phase transitions. We even show how our methods can be used to improve MLM performance by suppressing SAS briefly at the beginning of training. By questioning a seemingly settled result in interpretability, we developed a deeper understanding of MLM training.</p><p><em>All preceding discussion of the research on brood parasites comes from one of my favorite books, <a href=https://www.goodreads.com/en/book/show/22529402 target=_blank rel=noopener>Cuckoo: Cheating by Nature</a> by Nick Davies. I highly recommend it to anyone interested in a deep dive on the evolution of a single survival strategy.</em></p></div><time class="mt-12 mb-8 block text-xs text-gray-500 ltr:text-right rtl:text-left dark:text-gray-400" datetime=2023-09-17T00:00:00.000Z><span>Last updated on</span>
Sep 17, 2023</time><div class="container mx-auto prose prose-slate lg:prose-xl dark:prose-invert mt-5"><div class="max-w-prose print:hidden"><div class="flex justify-center"><a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href=/tags/training-dynamics/>Training Dynamics</a>
<a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href=/tags/interpretability/>Interpretability</a>
<a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href=/tags/manifesto/>Manifesto</a></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fnsaphra.net%2Fpost%2Fprinia%2F&amp;text=The+Parable+of+the+Prinia%27s+Egg%3A+An+Allegory+for+AI+Science" title=X aria-label=X id=share-link-x><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fnsaphra.net%2Fpost%2Fprinia%2F&amp;t=The+Parable+of+the+Prinia%27s+Egg%3A+An+Allegory+for+AI+Science" title=Facebook aria-label=Facebook id=share-link-facebook><svg style="height:1em" viewBox="0 0 24 24"><path fill="currentcolor" d="M22 12c0-5.52-4.48-10-10-10S2 6.48 2 12c0 4.84 3.44 8.87 8 9.8V15H8v-3h2V9.5C10 7.57 11.57 6 13.5 6H16v3h-2c-.55.0-1 .45-1 1v2h3v3h-3v6.95c5.05-.5 9-4.76 9-9.95z"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?subject=The%20Parable%20of%20the%20Prinia%27s%20Egg%3A%20An%20Allegory%20for%20AI%20Science&amp;body=https%3A%2F%2Fnsaphra.net%2Fpost%2Fprinia%2F" title=Email aria-label=Email id=share-link-email><svg style="height:1em" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5.0 11-9 0 4.5 4.5.0 019 0zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 10-2.636 6.364M16.5 12V8.25"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fnsaphra.net%2Fpost%2Fprinia%2F&amp;title=The+Parable+of+the+Prinia%27s+Egg%3A+An+Allegory+for+AI+Science" title=LinkedIn aria-label=LinkedIn id=share-link-linkedin><svg style="height:1em" height="1em" viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="whatsapp://send?text=The+Parable+of+the+Prinia%27s+Egg%3A+An+Allegory+for+AI+Science%20https%3A%2F%2Fnsaphra.net%2Fpost%2Fprinia%2F" title=WhatsApp aria-label=WhatsApp id=share-link-whatsapp><svg style="height:1em" viewBox="0 0 256 256" fill="currentcolor"><path d="m187.58 144.84-32-16a8 8 0 00-8 .5l-14.69 9.8a40.55 40.55.0 01-16-16l9.8-14.69a8 8 0 00.5-8l-16-32A8 8 0 00104 64a40 40 0 00-40 40 88.1 88.1.0 0088 88 40 40 0 0040-40 8 8 0 00-4.42-7.16zM152 176a72.08 72.08.0 01-72-72 24 24 0 0119.29-23.54l11.48 23L101 118a8 8 0 00-.73 7.51 56.47 56.47.0 0030.15 30.15A8 8 0 00138 155l14.61-9.74 23 11.48A24 24 0 01152 176zM128 24A104 104 0 0036.18 176.88l-11.35 34.05a16 16 0 0020.24 20.24l34.05-11.35A104 104 0 10128 24zm0 192a87.87 87.87.0 01-44.06-11.81 8 8 0 00-6.54-.67L40 216l12.47-37.4a8 8 0 00-.66-6.54A88 88 0 11128 216z"/></svg></a></section><div class="flex pt-12 pb-4"><img class="mr-4 h-24 w-24 rounded-full" width=96 height=96 alt="Naomi Saphra" src=/author/naomi-saphra/avatar_hu_f30f2983c45c7e09.jpg loading=lazy><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Authors</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300"><a href=https://nsaphra.net/ class=no-underline>Naomi Saphra</a></div><div class="text-sm font-bold text-neutral-700 dark:text-neutral-300">Research Fellow</div><div class="text-2xl sm:text-lg pt-1"><div class="flex flex-wrap text-neutral-500 dark:text-neutral-300"><a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=/ aria-label=At-Symbol><svg style="height:1em" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5.0 11-9 0 4.5 4.5.0 019 0zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 10-2.636 6.364M16.5 12V8.25"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://bsky.app/profile/nsaphra.bsky.social target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Brands/Bluesky><svg style="height:1em" viewBox="0 0 568 501"><path fill="currentcolor" d="M123.121 33.6637C188.241 82.5526 258.281 181.681 284 234.873c25.719-53.192 95.759-152.3204 160.879-201.2093C491.866-1.61183 568-28.9064 568 57.9464 568 75.2916 558.055 203.659 552.222 224.501c-20.275 72.453-94.155 90.933-159.875 79.748C507.222 323.8 536.444 388.56 473.333 453.32c-119.86 122.992-172.272-30.859-185.702-70.281C285.169 375.812 284.017 372.431 284 375.306 283.983 372.431 282.831 375.812 280.369 383.039c-13.43 39.422-65.842 193.273-185.7023 70.281C31.5556 388.56 60.7778 323.8 175.653 304.249 109.933 315.434 36.0535 296.954 15.7778 224.501 9.94525 203.659.0 75.2916.0 57.9464.0-28.9064 76.1345-1.61183 123.121 33.6637z"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://twitter.com/nsaphra target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Brands/X><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href="https://scholar.google.co.uk/citations?user=TPhVfX8AAAAJ" target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Academicons/Google-Scholar><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M343.759 106.662V79.43L363.524 64h-213.89L20.476 176.274h85.656a82.339 82.339.0 00-.219 6.225c0 20.845 7.22 38.087 21.672 51.861 14.453 13.797 32.252 20.648 53.327 20.648 4.923.0 9.75-.368 14.438-1.024-2.907 6.5-4.374 12.523-4.374 18.142.0 9.875 4.499 20.43 13.467 31.642-39.234 2.67-68.061 9.732-86.437 21.163-10.531 6.5-19 14.704-25.39 24.531-6.391 9.9-9.578 20.515-9.578 31.962.0 9.648 2.062 18.336 6.219 26.062 4.156 7.726 9.578 14.07 16.312 18.984 6.718 4.968 14.469 9.101 23.219 12.469 8.734 3.344 17.406 5.718 26.061 7.062A167.052 167.052.0 00180.555 448c13.469.0 26.953-1.734 40.547-5.187 13.562-3.485 26.28-8.642 38.171-15.493 11.86-6.805 21.515-16.086 28.922-27.718 7.39-11.68 11.094-24.805 11.094-39.336.0-11.016-2.25-21.039-6.75-30.14-4.468-9.073-9.938-16.542-16.452-22.345-6.501-5.813-13-11.155-19.516-15.968-6.5-4.845-12-9.75-16.468-14.813-4.485-5.046-6.735-10.054-6.735-14.984.0-4.921 1.734-9.672 5.216-14.265 3.455-4.61 7.674-9.048 12.61-13.306 4.937-4.25 9.875-8.968 14.796-14.133 4.922-5.147 9.141-11.827 12.61-20.008 3.485-8.18 5.203-17.445 5.203-27.757.0-13.453-2.547-24.46-7.547-33.314-.594-1.022-1.218-1.803-1.875-3.022l56.907-46.672v17.119c-7.393.93-6.624 5.345-6.624 10.635V245.96c0 5.958 4.875 10.834 10.834 10.834h3.989c5.958.0 10.833-4.875 10.833-10.834V117.293c0-5.277.778-9.688-6.561-10.63zm-107.36 222.48c1.14.75 3.704 2.78 7.718 6.038 4.05 3.243 6.797 5.695 8.266 7.414a443.553 443.553.0 016.376 7.547c2.813 3.375 4.718 6.304 5.718 8.734 1 2.477 2.016 5.461 3.047 8.946a38.27 38.27.0 011.485 10.562c0 17.048-6.564 29.68-19.656 37.859-13.125 8.18-28.767 12.274-46.938 12.274-9.187.0-18.203-1.093-27.063-3.196-8.843-2.116-17.311-5.336-25.39-9.601-8.078-4.258-14.577-10.204-19.5-17.797-4.938-7.64-7.407-16.415-7.407-26.25.0-10.32 2.797-19.29 8.422-26.906 5.594-7.625 12.938-13.391 22.032-17.315 9.063-3.946 18.25-6.742 27.562-8.398a157.865 157.865.0 0128.438-2.555c4.47.0 7.936.25 10.405.696.455.219 3.032 2.07 7.735 5.563 4.704 3.462 7.625 5.595 8.75 6.384zm-3.359-100.579c-7.406 8.86-17.734 13.288-30.953 13.288-11.86.0-22.298-4.764-31.266-14.312-9-9.523-15.422-20.328-19.344-32.43-3.937-12.109-5.906-23.984-5.906-35.648.0-13.694 3.596-25.352 10.781-34.976 7.187-9.65 17.5-14.485 30.938-14.485 11.875.0 22.374 5.038 31.437 15.157 9.094 10.085 15.61 21.413 19.517 33.968 3.922 12.54 5.873 24.53 5.873 35.984.0 13.446-3.702 24.61-11.076 33.454z"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://www.semanticscholar.org/author/Naomi-Saphra/2362960 target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Academicons/Semantic-Scholar><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M379.087 75.202c18.168 40.684 25.533 83.89 32.421 127.21-1.265.358-2.528.72-3.794 1.082-.91-2.534-1.984-5.021-2.707-7.61-5.218-18.653-10.48-37.296-15.474-56.011-1.797-6.733-6.035-10.084-12.096-13.381-8.901-4.842-17.313-11.084-24.69-18.046-4.707-4.44-8.735-7.149-15.413-7.078-44.46.47-88.925.515-133.384.924-2.963.03-6.63 1.124-8.728 3.065-8.089 7.484-15.671 15.514-25.642 25.556 26.3 64.04 39.522 133.84 33.845 208.044-12.626-8.084-22.4-14.48-22.981-31.418-2.904-84.661-29.02-161.225-83.58-227.108-1.228-1.482-1.838-3.476-2.738-5.23h284.96zM48.73 107.847c12.663.0 25.332-.2 37.984.172 2.51.072 6.022 1.668 7.277 3.68 37.836 60.79 67.334 124.635 71.155 197.682.018.29-.282.594-1.362 2.716-22.612-77.293-63.404-142.735-115.872-201.39.274-.952.545-1.906.819-2.86zM8 161.029c18.09-.658 33.39-1.318 48.692-1.602 1.541-.03 3.36 2.009 4.65 3.443 29.848 33.202 56.936 68.281 73.633 110.235 3.177 7.98 5.351 16.36 7.989 24.555C108.379 243.235 60.254 202.538 8 161.028zm194.474 275.77c-31.481-50.066-61.803-98.29-92.128-146.513l1.112-1.428c2.542 2.047 56.622 45.412 80.91 65.302 6.766 5.541 11.878 5.441 18.915-.274 82.584-67.085 174.737-117.862 272.583-158.809 5.223-2.185 10.64-3.916 15.983-5.816 1.186-.42 2.44-.654 4.151-.222-113.623 65.987-222.022 138.239-301.526 247.76z"/></svg></a></div></div></div></div><div class="pt-1 no-prose w-full"><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex flex-col md:flex-row flex-nowrap justify-between gap-5 pt-2"><div></div><div><a class="group flex text-right no-underline" href=/post/creationism/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Interpretability Creationism</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">Jun 7, 2022
</span></span><span class="mt-[-0.3rem] ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class=ltr:inline>&rarr;</span></span></a></div></div></div></div></div></main></article></div></div><div class=page-footer><footer class="container mx-auto flex flex-col justify-items-center text-sm leading-6 mt-24 mb-4 text-slate-700 dark:text-slate-200"><p class="powered-by text-center">© 2025 Me. This work is licensed under CC BY NC ND 4.0</p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class="powered-by text-center">Published with Hugo Blox Builder — the free, open source website builder that empowers creators.</p></footer></div></body></html>