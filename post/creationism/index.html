<!doctype html><html lang=en-us dir=ltr data-wc-theme-default=system><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 0.3.1"><meta name=author content="Naomi Saphra"><meta name=description content="Nothing in Deep Learning Makes Sense Except in the Light of SGD."><link rel=alternate hreflang=en-us href=https://nsaphra.github.io/post/creationism/><link rel=stylesheet href=/css/themes/emerald.min.css><link href=/dist/wc.min.css rel=stylesheet><script>window.hbb={defaultTheme:document.documentElement.dataset.wcThemeDefault,setDarkTheme:()=>{document.documentElement.classList.add("dark"),document.documentElement.style.colorScheme="dark"},setLightTheme:()=>{document.documentElement.classList.remove("dark"),document.documentElement.style.colorScheme="light"}},console.debug(`Default Hugo Blox Builder theme is ${window.hbb.defaultTheme}`),"wc-color-theme"in localStorage?localStorage.getItem("wc-color-theme")==="dark"?window.hbb.setDarkTheme():window.hbb.setLightTheme():(window.hbb.defaultTheme==="dark"?window.hbb.setDarkTheme():window.hbb.setLightTheme(),window.hbb.defaultTheme==="system"&&(window.matchMedia("(prefers-color-scheme: dark)").matches?window.hbb.setDarkTheme():window.hbb.setLightTheme()))</script><script>document.addEventListener("DOMContentLoaded",function(){let e=document.querySelectorAll("li input[type='checkbox'][disabled]");e.forEach(e=>{e.parentElement.parentElement.classList.add("task-list")});const t=document.querySelectorAll(".task-list li");t.forEach(e=>{let t=Array.from(e.childNodes).filter(e=>e.nodeType===3&&e.textContent.trim().length>1);if(t.length>0){const n=document.createElement("label");t[0].after(n),n.appendChild(e.querySelector("input[type='checkbox']")),n.appendChild(t[0])}})})</script><link rel=icon type=image/png href=/media/icon_hu_4d36134051bb7026.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu_d9b2d55b74fabcc9.png><link rel=canonical href=https://nsaphra.github.io/post/creationism/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@nsaphra"><meta property="twitter:creator" content="@nsaphra"><meta property="og:site_name" content="Naomi Saphra"><meta property="og:url" content="https://nsaphra.github.io/post/creationism/"><meta property="og:title" content="Interpretability Creationism | Naomi Saphra"><meta property="og:description" content="Nothing in Deep Learning Makes Sense Except in the Light of SGD."><meta property="og:image" content="https://nsaphra.github.io/media/icon_hu_ecc3d54b494abbac.png"><meta property="twitter:image" content="https://nsaphra.github.io/media/icon_hu_ecc3d54b494abbac.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2022-06-07T00:00:00+00:00"><meta property="article:modified_time" content="2022-06-07T00:00:00+00:00"><title>Interpretability Creationism | Naomi Saphra</title><style>@font-face{font-family:inter var;font-style:normal;font-weight:100 900;font-display:swap;src:url(/dist/font/Inter.var.woff2)format(woff2)}</style><link type=text/css rel=stylesheet href=/dist/pagefind/pagefind-ui.be766eb419317a14ec769d216e9779bfe8f3737c80e780f4ba0dafb57a41a482.css integrity="sha256-vnZutBkxehTsdp0hbpd5v+jzc3yA54D0ug2vtXpBpII="><script src=/dist/pagefind/pagefind-ui.87693d7c6f2b3b347ce359d0ede762c033419f0a32b22ce508c335a81d841f1b.js integrity="sha256-h2k9fG8rOzR841nQ7ediwDNBnwoysizlCMM1qB2EHxs="></script><script>window.hbb.pagefind={baseUrl:"/"}</script><style>html.dark{--pagefind-ui-primary:#eeeeee;--pagefind-ui-text:#eeeeee;--pagefind-ui-background:#152028;--pagefind-ui-border:#152028;--pagefind-ui-tag:#152028}</style><script>window.addEventListener("DOMContentLoaded",e=>{new PagefindUI({element:"#search",showSubResults:!0,baseUrl:window.hbb.pagefind.baseUrl,bundlePath:window.hbb.pagefind.baseUrl+"pagefind/"})}),document.addEventListener("DOMContentLoaded",()=>{let e=document.getElementById("search"),t=document.getElementById("search_toggle");t&&t.addEventListener("click",()=>{if(e.classList.toggle("hidden"),e.querySelector("input").value="",e.querySelector("input").focus(),!e.classList.contains("hidden")){let t=document.querySelector(".pagefind-ui__search-clear");t&&!t.hasAttribute("listenerOnClick")&&(t.setAttribute("listenerOnClick","true"),t.addEventListener("click",()=>{e.classList.toggle("hidden")}))}})})</script><link type=text/css rel=stylesheet href=/dist/lib/katex/katex.min.505d5f829022bb7b4f24dfee0aa1141cd7bba67afe411d1240335f820960b5c3.css integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM="><script defer src=/dist/lib/katex/katex.min.dc84b296ec3e884de093158f760fd9d45b6c7abe58b5381557f4e138f46a58ae.js integrity="sha256-3ISyluw+iE3gkxWPdg/Z1Ftser5YtTgVV/ThOPRqWK4="></script><script defer src=/js/katex-renderer.6579ec9683211cfb952064aedf3a3baea5eeb17a061775b32b70917474637c80.js integrity="sha256-ZXnsloMhHPuVIGSu3zo7rqXusXoGF3WzK3CRdHRjfIA="></script><script defer src=/js/hugo-blox-en.min.8c8ea06bd0420f5067e52fa727b9f92303757322ba4431774153d59a9735eadb.js integrity="sha256-jI6ga9BCD1Bn5S+nJ7n5IwN1cyK6RDF3QVPVmpc16ts="></script><script async defer src=https://buttons.github.io/buttons.js></script></head><body class="dark:bg-hb-dark dark:text-white page-wrapper" id=top><div id=page-bg></div><div class="page-header sticky top-0 z-30"><header id=site-header class=header><nav class="navbar px-3 flex justify-left"><div class="order-0 h-100"><a class=navbar-brand href=/ title="Naomi Saphra">Naomi Saphra</a></div><input id=nav-toggle type=checkbox class=hidden>
<label for=nav-toggle class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1"><svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20"><title>Open Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0V0z"/></svg><svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20"><title>Close Menu</title><polygon points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2" transform="rotate(45 10 10)"/></svg></label><ul id=nav-menu class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8 justify-left"><li class=nav-item><a class=nav-link href=/>Bio</a></li><li class=nav-item><a class=nav-link href=/#posts>Posts</a></li><li class=nav-item><a class=nav-link href=/#papers>Publications</a></li></ul><div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0"><button aria-label=search class="text-black hover:text-primary inline-block px-3 text-xl dark:text-white" id=search_toggle><svg height="16" width="16" viewBox="0 0 512 512" fill="currentcolor"><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8.0 45.3s-32.8 12.5-45.3.0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9.0 208S93.1.0 208 0 416 93.1 416 208zM208 352a144 144 0 100-288 144 144 0 100 288z"/></svg></button><div class="px-3 text-black hover:text-primary-700 dark:text-white dark:hover:text-primary-300
[&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white"><button class="theme-toggle mt-1" accesskey=t title=appearance><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="dark:hidden"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="dark:block [&:not(dark)]:hidden"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div></nav></header><div id=search class="hidden p-3"></div></div><div class="page-body my-10"><div class="mx-auto flex max-w-screen-xl"><aside class="hb-sidebar-container max-lg:[transform:translate3d(0,-100%,0)] lg:hidden xl:block"><div class="px-4 pt-4 lg:hidden"></div><div class="hb-scrollbar lg:h-[calc(100vh-var(--navbar-height))]"><ul class="flex flex-col gap-1 lg:hidden"><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/event/>Recent & Upcoming Talks
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/event/example/>Example Talk</a></li></ul></div></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/>Publications
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/hublog/>How to visualize training dynamics in neural networks</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/polypythias/>PolyPythias: Stability and Outliers across Fifty Language Model Pre-Training Runs</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/prashanth-2024-recitereconstructrecollectmemorization/>Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/systematicity/>Attribute Diversity Determines the Systematicity Gap in VQA</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/bench/>Benchmarks as Microscopes: A Call for Model Metrology</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/jenny/>Causation Does Not Imply Correlation: A Study of Circuit Mechanisms and Model Behaviors</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/li-2024-chatgptdoesnttrustchargers/>ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/rosie/>Distributional Scaling Laws for Emergent Capabilities</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/ankner/>Dynamic Masking Rate Schedules for MLM Pretraining</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/ff/>Fast Forwarding Low-Rank Training</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/parse/>First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sara-loss/>Loss in the Crowd: Hidden Breakthroughs in Language Model Training</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sarah-mech/>Mechanistic?</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sunny/>Sometimes I am a Tree: Data drives fragile hierarchical generalization</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/chen/>Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sherborne-tram-2023/>TRAM: Bridging Trust Regions and Sharpness Aware Minimization</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/zhang-2024-transcendence/>Transcendence: Generative Models Can Outperform The Experts That Train Them</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/johnson-yu-2024-understanding/>Understanding biological active sensing behaviors by interpreting learned artificial agent policies</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/hu/>Delays, Detours, and Forks in the Road: Latent State Models of Training Dynamics</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/saphra-2023-interp/>Interpretability Creationism</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/juneja-linear-2023/>Linear Connectivity Reveals Generalization Strategies</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/attrib/>Shapley Interactions for Complex Feature Attribution</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/hupkes-state-art-2023/>State-of-the-art generalisation research in NLP: a taxonomy and review</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sultan/>Towards out-of-distribution generalization in large-scale astronomical surveys: robust networks learn similar representations</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/valvoda-learning-2022/>Learning Transductions to Test Systematic Compositionality</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/zhao-one-2022/>One Venue, Two Conferences: The Separation of Chinese and American Citation Networks</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/sellam-multiberts-2021/>The MultiBERTs: BERT Reproductions for Robustness Analysis</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/white-nonlinear-2020/>A Non-Linear Structural Probe</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/saphra-lstms-2020/>LSTMs Compose---and Learn---Bottom-Up</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/pimentel-pareto-2020/>Pareto Probing: Trading Off Accuracy for Complexity</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/tahaei/>Understanding Privacy-Related Questions on Stack Overflow</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/kate/>Carbon AI and the Concentration of Computational Work</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/saphra-sparsity/>Sparsity Emerges Naturally in Neural Language Models</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/saphra-understand-2019/>Understanding Learning Dynamics Of Language Models with SVCCA</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/dynet/>DyNet: The Dynamic Neural Network Toolkit</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/pos-first/>Evaluating Informal-Domain Word Representations with UrbanDictionary</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/naomi-saphra-amrica-2015/>AMRICA: an AMR Inspector for Cross-language Alignments</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/schneider-framework-2014/>A framework for (under) specifying dependency syntax without overloading annotators</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/cotterell-algerian-2014/>An Algerian Arabic-French Code-Switched Corpus</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/vedaldi-understanding-2014/>Understanding Objects in Detail with Fine-grained Attributes</a></li></ul></div></li><li class=open><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/>Blog
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/prinia/>The Parable of the Prinia's Egg: An Allegory for AI Science</a></li><li class="flex flex-col open"><a class="hb-sidebar-custom-link
sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900" href=/post/creationism/>Interpretability Creationism</a><ul class=hb-sidebar-mobile-toc><li><a href=#just-so-stories class=hb-docs-link>Just-So Stories</a></li><li><a href=#the-evolutionary-view class=hb-docs-link>The Evolutionary View</a></li><li><a href=#an-example class=hb-docs-link>An Example</a></li><li><a href=#a-proposal class=hb-docs-link>A Proposal</a></li></ul></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/monodomainism/>Against Monodomainism</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/hands/>What Does a Coder Do If They Can't Type?</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/model-scheduling/>Model Scheduling</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/lda/>Understanding Latent Dirichlet Allocation</a></li></ul></div></li></ul><div class="max-xl:hidden h-0 w-64 shrink-0"></div></div></aside><nav class="hb-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents"><div class="hb-scrollbar text-sm [hyphens:auto] sticky top-16 overflow-y-auto pr-4 pt-6 max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] -mr-4 rtl:-ml-4"><p class="mb-4 font-semibold tracking-tight">On this page</p><ul><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#just-so-stories>Just-So Stories</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#the-evolutionary-view>The Evolutionary View</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#an-example>An Example</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#a-proposal>A Proposal</a></li></ul>
    
    
  </div></nav><article class="w-full break-words flex min-h-[calc(100vh-var(--navbar-height))] min-w-0 justify-center pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]"><main class="w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12"><h1 class="mt-2 text-4xl font-bold tracking-tight text-slate-900 dark:text-slate-100">Interpretability Creationism</h1><div class="mt-4 mb-16"><div class="text-gray-500 dark:text-gray-300 text-sm flex items-center flex-wrap gap-y-2"><span class=mr-1>Jun 7, 2022</span><span class=mx-1>·</span><div class="group inline-flex items-center text-current gap-x-1.5 mx-1"><img src=/author/naomi-saphra/avatar_hu_173659a9cfad1518.webp alt="Naomi Saphra" class="inline-block h-4 w-4 rounded-full border border-current" loading=lazy><div>Naomi Saphra</div></div><span class=mx-1>·</span>
<span class=mx-1>7 min read</span></div><div class=mt-3></div></div><div class="prose prose-slate lg:prose-xl dark:prose-invert"><p>For centuries, Europeans agreed that the presence of a cuckoo egg was a great honor to a nesting bird, as it granted an opportunity to exhibit Christian hospitality. The devout bird enthusiastically fed her holy guest, even more so than she would her own (evicted) chicks <a href=https://app.thestorygraph.com/books/37ed3b62-8a3a-448b-9e37-cd5e5f51c640 target=_blank rel=noopener>(Davies, 2015)</a>. In 1859, Charles Darwin’s studies of another occasional brood parasite, finches, called into question any rosy, cooperative view of bird behavior <a href=https://app.thestorygraph.com/books/44185106-8198-42ef-bacf-8a9bf691e654 target=_blank rel=noopener>(Darwin, 1859)</a>. Without considering the evolution of the cuckoo’s role, it would have been difficult to recognize the nesting bird not as a gracious host to the cuckoo chick, but as an unfortunate dupe. The historical process is essential to understanding its biological consequences; as evolutionary biologist Theodosius Dobzhansky put it, <a href=https://en.wikipedia.org/wiki/Nothing_in_Biology_Makes_Sense_Except_in_the_Light_of_Evolution#cite_note-Dobz_Nothing-1 target=_blank rel=noopener>Nothing in Biology Makes Sense Except in the Light of Evolution</a>.</p><p><figure><div class="flex justify-center"><div class=w-100><img src=https://upload.wikimedia.org/wikipedia/commons/5/5c/Reed_warbler_cuckoo.jpg alt="By Per Harald Olsen - Own work, CC BY-SA 3.0" loading=lazy data-zoomable></div></div></figure></p><p>Certainly SGD is not literally biological evolution, but post-hoc analysis in machine learning <a href=https://twitter.com/ch402/status/1533164918886703104 target=_blank rel=noopener>has a lot in common</a> with scientific approaches in biology, and likewise often requires an understanding of the origin of model behavior. Therefore, the following holds whether looking at parasitic brooding behavior or at the inner representations of a neural network: if we do not consider how a system develops, it is difficult to distinguish a pleasing story from a useful analysis.</p><h2 id=just-so-stories>Just-So Stories</h2><p>We have many pleasing <a href=https://en.wikipedia.org/wiki/Just_So_Stories target=_blank rel=noopener>just-so stories</a> in NLP. Much has been made of interpretable artifacts such as <a href=https://aclanthology.org/2022.acl-long.269.pdf target=_blank rel=noopener>syntactic attention distributions</a> or <a href=https://openai.com/blog/unsupervised-sentiment-neuron/ target=_blank rel=noopener>selective neurons</a>. But how can we know if such a pattern of behavior is actually used by the model?
Causal modeling can help, but interventions to test the influence of particular features and patterns may target only particular types of behavior explicitly. In practice, it may be possible only to perform certain types of slight interventions on specific units within a representation, failing to reflect interactions between features properly. Furthermore, in staging these interventions, we create distribution shifts that a model may not be robust to, regardless of whether that behavior is part of a core strategy. Significant distribution shifts can cause erratic behavior, so why shouldn&rsquo;t they cause spurious interpretable artifacts? In practice, we find <a href=https://arxiv.org/pdf/2010.12016.pdf target=_blank rel=noopener>no shortage</a> of incidental observations construed as crucial.</p><p>Fortunately, the study of evolution has provided a number of ways to interpret the artifacts produced by a model. They might be vestigial, like a human tailbone. They may have dependencies, with some features and structures relying on the presence of other properties earlier in training, like the requirement for light sensing before a complex eye can develop. Some artifacts might represent side effects of training, like how junk DNA constitutes a majority of our genetic code without influencing our phenotypes.</p><p>We have a number of theories for how such unused artifacts might emerge while training models. For example, the <a href=https://arxiv.org/abs/1703.00810 target=_blank rel=noopener>Information Bottleneck Hypothesis</a> predicts how inputs may be memorized early in training, before representations are compressed to only retain information about the output. These early memorized interpolations may not ultimately be useful when generalizing to unseen data, but they are essential in order to eventually learn to specifically represent the output. We also can infer the possibility of vestigial features, because early training behavior is so distinct from late training: <a href=http://arxiv.org/abs/1905.11604 target=_blank rel=noopener>earlier models are more simplistic</a>. In the case of language models, they <a href=http://arxiv.org/abs/2109.06096 target=_blank rel=noopener>behave similarly to ngram models</a> early on and <a href=https://www.aclweb.org/anthology/2020.emnlp-main.16 target=_blank rel=noopener>exhibit linguistic patterns</a> later. Side effects of such a heteroskedastic training process could easily be mistaken for crucial components of a trained model.</p><h2 id=the-evolutionary-view>The Evolutionary View</h2><p>I may be unimpressed by &ldquo;interpretability creationist&rdquo; explanations of static fully trained models, but I have engaged in similar analysis myself. I&rsquo;ve published papers on <a href=https://arxiv.org/pdf/2010.02180.pdf target=_blank rel=noopener>probing static representations</a>, and the results often seem intuitive and explanatory. However, the presence of a feature at the end of training is hardly informative about the inductive bias of a model on its own! Consider <a href="https://openreview.net/forum?id=mNtmhaDkAr" target=_blank rel=noopener>Lovering et al.</a>, who found that the ease of extracting a feature at the start of training, along with an analysis of the finetuning data, has deeper implications for finetuned performance than we get by simply probing at the end of training.</p><p>Let us consider an explanation usually based on analyzing static models: hierarchical behavior in language models. An example of this approach is the claim that <a href=https://nlp.stanford.edu/pubs/hewitt2019structural.pdf target=_blank rel=noopener>words that are closely linked on a syntax tree have representations that are closer together</a>, compared to words that are syntactically farther. How can we know that the model is behaving hierarchically by grouping words according to syntactic proximity? Alternatively, syntactic neighbors may be more strongly linked due to a strong correlation between nearby words because they have higher joint frequency distributions. For example, perhaps constituents like &ldquo;football match&rdquo; are more predictable due to the frequency of their co-occurrence, compared to more distant relations like that between &ldquo;uncle&rdquo; and &ldquo;football&rdquo; in the sentence, &ldquo;My uncle drove me to a football match&rdquo;. In fact, we can be more confident that some language models are hierarchical, because early models encode more local information in <a href=https://arxiv.org/abs/1811.00225 target=_blank rel=noopener>LSTMs</a> and <a href=https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html#argument-phase-change target=_blank rel=noopener>Transformers</a>, and they learn longer distance dependencies more easily when those dependencies can be <a href=https://arxiv.org/abs/2010.04650 target=_blank rel=noopener>stacked onto short familiar constituents</a> hierarchically.</p><h2 id=an-example>An Example</h2><p>I recently had to manage the trap of interpretability creationism myself. My coauthors had found that, when training text classifiers repeatedly with different random seeds, <a href=https://arxiv.org/abs/2205.12411 target=_blank rel=noopener>models can occur in a number of distinct clusters</a>. Further, we could predict the generalization behavior of a model based on which other models it was connected to on the loss surface. Now, we suspected that different finetuning runs found models with different generalization behavior because their trajectories entered different basins on the loss surface.</p><p>But could we actually make this claim? What if one cluster actually corresponded to earlier stages of a model? Eventually those models would leave for the cluster with better generalization, so our only real result would be that some finetuning runs were slower than others. We had to demonstrate that training trajectories could actually become trapped in a basin, providing an explanation for the diversity of generalization behavior in trained models. Indeed, when we looked at several checkpoints, we confirmed that models that were very central to either cluster would become <em>even more</em> strongly connected to the rest of their cluster over the course of training. Instead of offering a just-so story based on a static model, we explored the evolution of observed behavior to confirm our hypothesis.</p><p><figure><div class="flex justify-center"><div class=w-100><img src=/images/qqp_training.png alt=k loading=lazy data-zoomable></div></div></figure></p><h2 id=a-proposal>A Proposal</h2><p>To be clear, not every question can be answered by <em>only</em> observing the training process. Causal claims require interventions! In biology, for example, research about antibiotic resistance requires us to deliberately expose bacteria to antibiotics, rather than waiting and hoping to find a natural experiment. Even the claims currently being made based on observations of training dynamics may require experimental confirmation.</p><p>Furthermore, not all claims require <em>any</em> observation of the training process. Even to ancient humans, many organs had obvious purpose: eyes see, hearts pump blood, and <a href=https://www.scientificamerican.com/article/aristotle-thought-the-brain-was-a-radiator/ target=_blank rel=noopener>brains are refrigerators</a>. Likewise in NLP, just by analyzing static models we can make simple claims: that particular neurons activate in the presence of particular properties, or that some types of information remain accessible within a model. However, the training dimension can still clarify the meaning of many observations made in a static model.</p><p>My proposal is simple. Are you developing a method of interpretation or analyzing some property of a trained model? Don&rsquo;t just look at final checkpoint in training. Apply that analysis to several intermediate checkpoints. If you are finetuning a model, check several points both early and late in training. If you are analyzing a large language model, <a href=https://arxiv.org/abs/2106.16163 target=_blank rel=noopener>MultiBERTs</a> and <a href=https://nlp.stanford.edu/mistral/getting_started/download.html target=_blank rel=noopener>Mistral</a> both provide intermediate checkpoints sampled from throughout training on masked and autoregressive language models, respectively. Does the behavior that you&rsquo;ve analyzed change over the course of training? Does your belief about the model&rsquo;s strategy actually make sense after observing what happens early in training? There&rsquo;s very little overhead to an experiment like this, and you never know what you&rsquo;ll find!</p></div><time class="mt-12 mb-8 block text-xs text-gray-500 ltr:text-right rtl:text-left dark:text-gray-400" datetime=2022-06-07T00:00:00.000Z><span>Last updated on</span>
Jun 7, 2022</time><div class="container mx-auto prose prose-slate lg:prose-xl dark:prose-invert mt-5"><div class="max-w-prose print:hidden"><div class="flex justify-center"><a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href=/tags/training-dynamics/>Training Dynamics</a>
<a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href=/tags/manifesto/>Manifesto</a></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fnsaphra.github.io%2Fpost%2Fcreationism%2F&amp;text=Interpretability+Creationism" title=X aria-label=X id=share-link-x><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fnsaphra.github.io%2Fpost%2Fcreationism%2F&amp;t=Interpretability+Creationism" title=Facebook aria-label=Facebook id=share-link-facebook><svg style="height:1em" viewBox="0 0 24 24"><path fill="currentcolor" d="M22 12c0-5.52-4.48-10-10-10S2 6.48 2 12c0 4.84 3.44 8.87 8 9.8V15H8v-3h2V9.5C10 7.57 11.57 6 13.5 6H16v3h-2c-.55.0-1 .45-1 1v2h3v3h-3v6.95c5.05-.5 9-4.76 9-9.95z"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?subject=Interpretability%20Creationism&amp;body=https%3A%2F%2Fnsaphra.github.io%2Fpost%2Fcreationism%2F" title=Email aria-label=Email id=share-link-email><svg style="height:1em" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5.0 11-9 0 4.5 4.5.0 019 0zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 10-2.636 6.364M16.5 12V8.25"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fnsaphra.github.io%2Fpost%2Fcreationism%2F&amp;title=Interpretability+Creationism" title=LinkedIn aria-label=LinkedIn id=share-link-linkedin><svg style="height:1em" height="1em" viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="whatsapp://send?text=Interpretability+Creationism%20https%3A%2F%2Fnsaphra.github.io%2Fpost%2Fcreationism%2F" title=WhatsApp aria-label=WhatsApp id=share-link-whatsapp><svg style="height:1em" viewBox="0 0 256 256" fill="currentcolor"><path d="m187.58 144.84-32-16a8 8 0 00-8 .5l-14.69 9.8a40.55 40.55.0 01-16-16l9.8-14.69a8 8 0 00.5-8l-16-32A8 8 0 00104 64a40 40 0 00-40 40 88.1 88.1.0 0088 88 40 40 0 0040-40 8 8 0 00-4.42-7.16zM152 176a72.08 72.08.0 01-72-72 24 24 0 0119.29-23.54l11.48 23L101 118a8 8 0 00-.73 7.51 56.47 56.47.0 0030.15 30.15A8 8 0 00138 155l14.61-9.74 23 11.48A24 24 0 01152 176zM128 24A104 104 0 0036.18 176.88l-11.35 34.05a16 16 0 0020.24 20.24l34.05-11.35A104 104 0 10128 24zm0 192a87.87 87.87.0 01-44.06-11.81 8 8 0 00-6.54-.67L40 216l12.47-37.4a8 8 0 00-.66-6.54A88 88 0 11128 216z"/></svg></a></section><div class="flex pt-12 pb-4"><img class="mr-4 h-24 w-24 rounded-full" width=96 height=96 alt="Naomi Saphra" src=/author/naomi-saphra/avatar_hu_f30f2983c45c7e09.jpg loading=lazy><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Authors</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300"><a href=https://nsaphra.github.io/ class=no-underline>Naomi Saphra</a></div><div class="text-sm font-bold text-neutral-700 dark:text-neutral-300">Research Fellow</div><div class="text-2xl sm:text-lg pt-1"><div class="flex flex-wrap text-neutral-500 dark:text-neutral-300"><a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=/ aria-label=At-Symbol><svg style="height:1em" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5.0 11-9 0 4.5 4.5.0 019 0zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 10-2.636 6.364M16.5 12V8.25"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://bsky.app/profile/nsaphra.bsky.social target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Brands/Bluesky><svg style="height:1em" viewBox="0 0 568 501"><path fill="currentcolor" d="M123.121 33.6637C188.241 82.5526 258.281 181.681 284 234.873c25.719-53.192 95.759-152.3204 160.879-201.2093C491.866-1.61183 568-28.9064 568 57.9464 568 75.2916 558.055 203.659 552.222 224.501c-20.275 72.453-94.155 90.933-159.875 79.748C507.222 323.8 536.444 388.56 473.333 453.32c-119.86 122.992-172.272-30.859-185.702-70.281C285.169 375.812 284.017 372.431 284 375.306 283.983 372.431 282.831 375.812 280.369 383.039c-13.43 39.422-65.842 193.273-185.7023 70.281C31.5556 388.56 60.7778 323.8 175.653 304.249 109.933 315.434 36.0535 296.954 15.7778 224.501 9.94525 203.659.0 75.2916.0 57.9464.0-28.9064 76.1345-1.61183 123.121 33.6637z"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://twitter.com/nsaphra target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Brands/X><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href="https://scholar.google.co.uk/citations?user=TPhVfX8AAAAJ" target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Academicons/Google-Scholar><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M343.759 106.662V79.43L363.524 64h-213.89L20.476 176.274h85.656a82.339 82.339.0 00-.219 6.225c0 20.845 7.22 38.087 21.672 51.861 14.453 13.797 32.252 20.648 53.327 20.648 4.923.0 9.75-.368 14.438-1.024-2.907 6.5-4.374 12.523-4.374 18.142.0 9.875 4.499 20.43 13.467 31.642-39.234 2.67-68.061 9.732-86.437 21.163-10.531 6.5-19 14.704-25.39 24.531-6.391 9.9-9.578 20.515-9.578 31.962.0 9.648 2.062 18.336 6.219 26.062 4.156 7.726 9.578 14.07 16.312 18.984 6.718 4.968 14.469 9.101 23.219 12.469 8.734 3.344 17.406 5.718 26.061 7.062A167.052 167.052.0 00180.555 448c13.469.0 26.953-1.734 40.547-5.187 13.562-3.485 26.28-8.642 38.171-15.493 11.86-6.805 21.515-16.086 28.922-27.718 7.39-11.68 11.094-24.805 11.094-39.336.0-11.016-2.25-21.039-6.75-30.14-4.468-9.073-9.938-16.542-16.452-22.345-6.501-5.813-13-11.155-19.516-15.968-6.5-4.845-12-9.75-16.468-14.813-4.485-5.046-6.735-10.054-6.735-14.984.0-4.921 1.734-9.672 5.216-14.265 3.455-4.61 7.674-9.048 12.61-13.306 4.937-4.25 9.875-8.968 14.796-14.133 4.922-5.147 9.141-11.827 12.61-20.008 3.485-8.18 5.203-17.445 5.203-27.757.0-13.453-2.547-24.46-7.547-33.314-.594-1.022-1.218-1.803-1.875-3.022l56.907-46.672v17.119c-7.393.93-6.624 5.345-6.624 10.635V245.96c0 5.958 4.875 10.834 10.834 10.834h3.989c5.958.0 10.833-4.875 10.833-10.834V117.293c0-5.277.778-9.688-6.561-10.63zm-107.36 222.48c1.14.75 3.704 2.78 7.718 6.038 4.05 3.243 6.797 5.695 8.266 7.414a443.553 443.553.0 016.376 7.547c2.813 3.375 4.718 6.304 5.718 8.734 1 2.477 2.016 5.461 3.047 8.946a38.27 38.27.0 011.485 10.562c0 17.048-6.564 29.68-19.656 37.859-13.125 8.18-28.767 12.274-46.938 12.274-9.187.0-18.203-1.093-27.063-3.196-8.843-2.116-17.311-5.336-25.39-9.601-8.078-4.258-14.577-10.204-19.5-17.797-4.938-7.64-7.407-16.415-7.407-26.25.0-10.32 2.797-19.29 8.422-26.906 5.594-7.625 12.938-13.391 22.032-17.315 9.063-3.946 18.25-6.742 27.562-8.398a157.865 157.865.0 0128.438-2.555c4.47.0 7.936.25 10.405.696.455.219 3.032 2.07 7.735 5.563 4.704 3.462 7.625 5.595 8.75 6.384zm-3.359-100.579c-7.406 8.86-17.734 13.288-30.953 13.288-11.86.0-22.298-4.764-31.266-14.312-9-9.523-15.422-20.328-19.344-32.43-3.937-12.109-5.906-23.984-5.906-35.648.0-13.694 3.596-25.352 10.781-34.976 7.187-9.65 17.5-14.485 30.938-14.485 11.875.0 22.374 5.038 31.437 15.157 9.094 10.085 15.61 21.413 19.517 33.968 3.922 12.54 5.873 24.53 5.873 35.984.0 13.446-3.702 24.61-11.076 33.454z"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://www.semanticscholar.org/author/Naomi-Saphra/2362960 target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Academicons/Semantic-Scholar><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M379.087 75.202c18.168 40.684 25.533 83.89 32.421 127.21-1.265.358-2.528.72-3.794 1.082-.91-2.534-1.984-5.021-2.707-7.61-5.218-18.653-10.48-37.296-15.474-56.011-1.797-6.733-6.035-10.084-12.096-13.381-8.901-4.842-17.313-11.084-24.69-18.046-4.707-4.44-8.735-7.149-15.413-7.078-44.46.47-88.925.515-133.384.924-2.963.03-6.63 1.124-8.728 3.065-8.089 7.484-15.671 15.514-25.642 25.556 26.3 64.04 39.522 133.84 33.845 208.044-12.626-8.084-22.4-14.48-22.981-31.418-2.904-84.661-29.02-161.225-83.58-227.108-1.228-1.482-1.838-3.476-2.738-5.23h284.96zM48.73 107.847c12.663.0 25.332-.2 37.984.172 2.51.072 6.022 1.668 7.277 3.68 37.836 60.79 67.334 124.635 71.155 197.682.018.29-.282.594-1.362 2.716-22.612-77.293-63.404-142.735-115.872-201.39.274-.952.545-1.906.819-2.86zM8 161.029c18.09-.658 33.39-1.318 48.692-1.602 1.541-.03 3.36 2.009 4.65 3.443 29.848 33.202 56.936 68.281 73.633 110.235 3.177 7.98 5.351 16.36 7.989 24.555C108.379 243.235 60.254 202.538 8 161.028zm194.474 275.77c-31.481-50.066-61.803-98.29-92.128-146.513l1.112-1.428c2.542 2.047 56.622 45.412 80.91 65.302 6.766 5.541 11.878 5.441 18.915-.274 82.584-67.085 174.737-117.862 272.583-158.809 5.223-2.185 10.64-3.916 15.983-5.816 1.186-.42 2.44-.654 4.151-.222-113.623 65.987-222.022 138.239-301.526 247.76z"/></svg></a></div></div></div></div><div class="pt-1 no-prose w-full"><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex flex-col md:flex-row flex-nowrap justify-between gap-5 pt-2"><div><a class="group flex no-underline" href=/post/prinia/><span class="mt-[-0.3rem] me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">The Parable of the Prinia's Egg: An Allegory for AI Science</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">Sep 17, 2023</span></span></a></div><div><a class="group flex text-right no-underline" href=/post/monodomainism/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Against Monodomainism</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">Apr 28, 2021
</span></span><span class="mt-[-0.3rem] ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class=ltr:inline>&rarr;</span></span></a></div></div></div></div></div></main></article></div></div><div class=page-footer><footer class="container mx-auto flex flex-col justify-items-center text-sm leading-6 mt-24 mb-4 text-slate-700 dark:text-slate-200"><p class="powered-by text-center">© 2025 Me. This work is licensed under CC BY NC ND 4.0</p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class="powered-by text-center">Published with Hugo Blox Builder — the free, open source website builder that empowers creators.</p></footer></div></body></html>