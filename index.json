[{"authors":null,"categories":null,"content":" I am a current postdoctoral researcher at NYU with Kyunghyun Cho, and an incoming 2023 Kempner Fellow at Harvard. I am interested in NLP training dynamics: how models learn to encode linguistic patterns or other structure and how we can encode useful inductive biases into the training process. Previously, I earned a PhD from the University of Edinburgh on Training Dynamics of Neural Language Models, worked at Google and Facebook, and attended Johns Hopkins and Carnegie Mellon University. Outside of research, I play roller derby under the name Gaussian Retribution, do standup comedy, and shepherd disabled programmers into the world of code dictation.\n","date":1696118400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1689644354,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a current postdoctoral researcher at NYU with Kyunghyun Cho, and an incoming 2023 Kempner Fellow at Harvard. I am interested in NLP training dynamics: how models learn to encode linguistic patterns or other structure and how we can encode useful inductive biases into the training process.","tags":null,"title":"Naomi Saphra","type":"authors"},{"authors":["Dieuwke Hupkes","Mario Giulianelli","Verna Dankers","Mikel Artetxe","Yanai Elazar","Tiago Pimentel","Christos Christodoulopoulos","Karim Lasri","Naomi Saphra","Arabella Sinclair","Dennis Ulmer","Florian Schottmann","Khuyagbaatar Batsuren","Kaiser Sun","Koustuv Sinha","Leila Khalatbari","Maria Ryskina","Rita Frieske","Ryan Cotterell","Zhijing Jin"],"categories":[],"content":"","date":1696118400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672373752,"objectID":"9b31cfe4e02e396ebbd6422c0f411716","permalink":"https://nsaphra.github.io/publication/hupkes-state-art-2022/","publishdate":"2022-12-30T04:15:52.031527Z","relpermalink":"/publication/hupkes-state-art-2022/","section":"publication","summary":"The ability to generalise well is one of the primary desiderata of natural language processing (NLP). Yet, what `good generalisation' entails and how it should be evaluated is not well understood, nor are there any common standards to evaluate it. In this paper, we aim to lay the ground-work to improve both of these issues. We present a taxonomy for characterising and understanding generalisation research in NLP, we use that taxonomy to present a comprehensive map of published generalisation studies, and we make recommendations for which areas might deserve attention in the future. Our taxonomy is based on an extensive literature review of generalisation research, and contains five axes along which studies can differ: their main motivation, the type of generalisation they aim to solve, the type of data shift they consider, the source by which this data shift is obtained, and the locus of the shift within the modelling pipeline. We use our taxonomy to classify over 400 previous papers that test generalisation, for a total of more than 600 individual experiments. Considering the results of this review, we present an in-depth analysis of the current state of generalisation research in NLP, and make recommendations for the future. Along with this paper, we release a webpage where the results of our review can be dynamically explored, and which we intend to up-date as new NLP generalisation studies are published. With this work, we aim to make steps towards making state-of-the-art generalisation testing the new status quo in NLP.","tags":["Computer Science - Artificial Intelligence","Computer Science - Computation and Language"],"title":"State-of-the-art generalisation research in NLP: a taxonomy and review","type":"publication"},{"authors":[],"categories":[],"content":" When European scientists first encountered the eggs of the tawny-flanked prinia Prinia subflava, an African nesting bird, they believed they understood what they had encountered. The prinia lay eggs that exhibited swirls, speckles, and coloration unique to each individual bird. What purpose do such patterns serve in nature? Surely, scientists agreed, these markings allowed the eggs to camouflage and blend into the nest.\nOne 19th century naturalist, Charles Francis Massey Swynnerton, offered an alternative explanation. Why would each bird have its own unique patterns? Swynnerton believed that the markings functioned as watermarks, allowing the nesting bird to differentiate its own eggs from those of the cuckoo finch Anomalospiza imberbis. The cuckoo finch is an obligate brood parasite, meaning that it does not build its own nest, but instead lays its eggs in the nests of other birds, particularly the prinia.\nSince its proposal, evidence for Swynnerton’s hypothesis has accumulated.The camouflage hypothesis was based on anecdotal observations of eggs, without correlational or experimental data. In contrast, evidence for the brood parasite hypothesis comes in diverse forms, using many different frameworks for reasoning about causality and explanation, adding up to an indisputable scientific arsenal. What can AI researchers learn from the mature science of biology to strengthen our own evidence and reliably interpret how neural network traits contribute to model behavior?\nInstance level interpretability Most interpretability work, and much work in science of deep learning, relies on passive observations of phenomena with post-hoc explanations for how artifacts in the model contribute to model outputs. Like the early ornithologists suggesting that prinia eggs were camouflaged, interpretability researchers often identify some phenomenon and link it to model decisions based solely on their intuitions. Some work attempts a more principled approach, by intervening on the trained model to demonstrate that a given feature or circuit has a predictable effect on model judgment. Both approaches might be classed as instance-level, as they consider the behavior of a fully trained model on a given input sample.\nIn the past, I have called this reliance on fully trained models Interpretability Creationism, and suggested that interpretability researchers instead measure the indicators they focus on throughout training. However, I have not detailed how these creationist approaches can lead us astray, nor have I proposed a clear framework for understanding development. Such a framework falls under the philosophical field of epistemology, the study of what makes a belief justified.\nSyntactic Attention Structure To address the epistemology of interpretability, let us construct a case study of the scientific literature on an observed phenomenon in neural networks. One well-documented and intuitive behavior is how Transformer-based masked language models (MLMs) have specialized attention heads that focus on a specific dependency relation, a trait we will call Syntactic Attention Structure (SAS). We can illustrate SAS with an example sentence.\nIn the preceding sentence, the model might be called upon to predict the masked-out target word builds. During inference, its specialized nsubj head will place its highest weight on bird, while its specialized dobj head will place its highest weight on nests. This specialization behavior emerges naturally, without any explicit inductive bias, over the normal course of training for models like BERT.\nSAS was discovered concurrently in two papers. First, Clark et al. (2019) observed that specialized attention heads provide an implicit parse, which aligns with prior notions of dependency syntax, as measured by Unlabeled Attachment Score (UAS). This observation provides instance-level observational evidence for the role of SAS in masked language modeling. Second, Voita et al. (2019) discovered that pruning specialized syntactic heads damaged model performance more than pruning other heads, providing instance-level causal evidence for the role of SAS. What’s missing from these studies, from an epistemological standpoint?\nWhen does instance-level analysis fail? There is an assumption underlying claims in interpretability: that the observed phenomenon measured by the interpretable indicator metric, such as implicit parse UAS, plays a role in determining some target metric, such as MLM validation loss or grammatical capabilities. However, instance-level evidence like the prior work on SAS might not support this assumption.\nFirst, instance-level observational evidence might highlight artifacts that arose as a side effect of training, rather than as a crucial element in model decisions. That is, the poorly-understood dynamics of training might lead to structures emerging that are not required at test time. In evolutionary biology, such artifacts are called spandrels; proposed examples include human chins …","date":1694884302,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694884302,"objectID":"7c21fb1311bacc9e9610bb7ddb198485","permalink":"https://nsaphra.github.io/post/prinia/","publishdate":"2023-09-16T18:11:42+01:00","relpermalink":"/post/prinia/","section":"post","summary":"I discuss what counts as strong evidence for an explanation of model behavior.","tags":["training dynamics","interpretability"],"title":"The Parable of the Prinia’s Egg: An Allegory for AI Science","type":"post"},{"authors":["Jeevesh Juneja","Rachit Bansal","Kyunghyun Cho","João Sedoc","Naomi Saphra"],"categories":null,"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682899200,"objectID":"81d49cdc2a9c4ddae2df920f81b4a71b","permalink":"https://nsaphra.github.io/publication/juneja-linear-2022/","publishdate":"2022-06-01T18:43:51.338959Z","relpermalink":"/publication/juneja-linear-2022/","section":"publication","summary":"It is widely accepted in the mode connectivity literature that when two neural networks are trained similarly on the same data, they are connected by a path through parameter space over which test set accuracy is maintained. Under some circumstances, including transfer learning from pretrained models, these paths are presumed to be linear. In contrast to existing results, we find that among text classifiers (trained on MNLI, QQP, and CoLA), some pairs of finetuned models have large barriers of increasing loss on the linear paths between them. On each task, we find distinct clusters of models which are linearly connected on the test loss surface, but are disconnected from models outside the cluster -- models that occupy separate basins on the surface. By measuring performance on specially-crafted diagnostic datasets, we find that these clusters correspond to different generalization strategies: one cluster behaves like a bag of words model under domain shift, while another cluster uses syntactic heuristics. Our work demonstrates how the geometry of the loss surface can guide models towards different heuristic functions.","tags":null,"title":"Linear Connectivity Reveals Generalization Strategies","type":"publication"},{"authors":["Zachary Ankner","Naomi Saphra","Davis Blalock","Jonathan Frankle","Matthew L. Leavitt"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689644193,"objectID":"8124643edcbe2a0bc3d94b7693eb809f","permalink":"https://nsaphra.github.io/publication/ankner/","publishdate":"2023-07-18T01:36:33.109294Z","relpermalink":"/publication/ankner/","section":"publication","summary":"","tags":[],"title":"Dynamic Masking Rate Schedules for MLM Pretraining","type":"publication"},{"authors":["Naomi Saphra"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689644354,"objectID":"1d0a9d7e8404745b0d26cb6635380da6","permalink":"https://nsaphra.github.io/publication/saphra-2023-interp/","publishdate":"2023-07-18T01:39:14.003172Z","relpermalink":"/publication/saphra-2023-interp/","section":"publication","summary":"","tags":[],"title":"Interpretability Creationism","type":"publication"},{"authors":["Michael Hu","Angelica Chen","Naomi Saphra","Kyunghyun Cho"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689644193,"objectID":"183c8950769d5420ec1ec247980d8e7b","permalink":"https://nsaphra.github.io/publication/hu-latent/","publishdate":"2023-07-18T01:36:32.831191Z","relpermalink":"/publication/hu-latent/","section":"publication","summary":"","tags":["workshop"],"title":"Latent State Transitions in Training Dynamics","type":"publication"},{"authors":["Bingchen Zhao","Yuling Gu","Jessica Zosa Forde","Naomi Saphra"],"categories":null,"content":"","date":1669420800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669420800,"objectID":"b27793823cb3981afced85ffdd8ee0ca","permalink":"https://nsaphra.github.io/publication/zhao-one-2022/","publishdate":"2022-11-26T00:00:00Z","relpermalink":"/publication/zhao-one-2022/","section":"publication","summary":"At NeurIPS, American and Chinese institutions cite papers from each other's regions substantially less than they cite endogamously. We build a citation graph to quantify this divide, compare it to European connectivity, and discuss the causes and consequences of the separation.","tags":["Meta"],"title":"One Venue, Two Conferences: The Separation of Chinese and American Citation Networks","type":"publication"},{"authors":null,"categories":null,"content":"","date":165573e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":165573e4,"objectID":"e6eddf8b6fbf57d02086fbf9e7dc6537","permalink":"https://nsaphra.github.io/talk/sources-of-variance-in-pretraining-and-finetuning/","publishdate":"2022-06-20T13:00:00Z","relpermalink":"/talk/sources-of-variance-in-pretraining-and-finetuning/","section":"event","summary":"You have engaged in the very modern practice of transfer learning. You pretrained a model on a self-supervised objective, then you finetuned it on a downstream task, and you find excellent performance on the test set. 'Aha', you say. 'I found a good pretraining procedure.' Did you? You try finetuning again. The results are terrible! 'Aha', you say. 'I found a bad finetuning procedure.' Did you?\n\nThe random seeds for both pretraining and finetuning stages have a substantial influence on outcome. However, it is computationally expensive to pretrain new models, so measuring the robustness of a procedure across different seeds can be prohibitive. This talk will address, first, the influence that a pretraining seed has on both in-domain and OOD performance. Then we will address the role of the finetuning seed. Much variation in OOD generalization can be ascribed to where the finetuning seeds direct SGD trajectories. In particular, we discuss how to predict generalization behavior in a finetuned model, based on topographic properties of its region of the loss surface.  By understanding the degree of influence that random seeds have on performance, we can fairly evaluate a robust training procedure, rather than a single set of parameters. By understanding the mechanism of that influence, we can go further by developing improved training methods.","tags":[],"title":"Sources of Variance in Pretraining and Finetuning","type":"event"},{"authors":["Naomi Saphra"],"categories":[],"content":"For centuries, Europeans agreed that the presence of a cuckoo egg was a great honor to a nesting bird, as it granted an opportunity to exhibit Christian hospitality. The devout bird enthusiastically fed her holy guest, even more so than she would her own (evicted) chicks (Davies, 2015). In 1859, Charles Darwin’s studies of another occasional brood parasite, finches, called into question any rosy, cooperative view of bird behavior (Darwin, 1859). Without considering the evolution of the cuckoo’s role, it would have been difficult to recognize the nesting bird not as a gracious host to the cuckoo chick, but as an unfortunate dupe. The historical process is essential to understanding its biological consequences; as evolutionary biologist Theodosius Dobzhansky put it, Nothing in Biology Makes Sense Except in the Light of Evolution.\nCertainly SGD is not literally biological evolution, but post-hoc analysis in machine learning has a lot in common with scientific approaches in biology, and likewise often requires an understanding of the origin of model behavior. Therefore, the following holds whether looking at parasitic brooding behavior or at the inner representations of a neural network: if we do not consider how a system develops, it is difficult to distinguish a pleasing story from a useful analysis.\nJust-So Stories We have many pleasing just-so stories in NLP. Much has been made of interpretable artifacts such as syntactic attention distributions or selective neurons. But how can we know if such a pattern of behavior is actually used by the model? Causal modeling can help, but interventions to test the influence of particular features and patterns may target only particular types of behavior explicitly. In practice, it may be possible only to perform certain types of slight interventions on specific units within a representation, failing to reflect interactions between features properly. Furthermore, in staging these interventions, we create distribution shifts that a model may not be robust to, regardless of whether that behavior is part of a core strategy. Significant distribution shifts can cause erratic behavior, so why shouldn’t they cause spurious interpretable artifacts? In practice, we find no shortage of incidental observations construed as crucial.\nFortunately, the study of evolution has provided a number of ways to interpret the artifacts produced by a model. They might be vestigial, like a human tailbone. They may have dependencies, with some features and structures relying on the presence of other properties earlier in training, like the requirement for light sensing before a complex eye can develop. Some artifacts might represent side effects of training, like how junk DNA constitutes a majority of our genetic code without influencing our phenotypes.\nWe have a number of theories for how such unused artifacts might emerge while training models. For example, the Information Bottleneck Hypothesis predicts how inputs may be memorized early in training, before representations are compressed to only retain information about the output. These early memorized interpolations may not ultimately be useful when generalizing to unseen data, but they are essential in order to eventually learn to specifically represent the output. We also can infer the possibility of vestigial features, because early training behavior is so distinct from late training: earlier models are more simplistic. In the case of language models, they behave similarly to ngram models early on and exhibit linguistic patterns later. Side effects of such a heteroskedastic training process could easily be mistaken for crucial components of a trained model.\nThe Evolutionary View I may be unimpressed by “interpretability creationist” explanations of static fully trained models, but I have engaged in similar analysis myself. I’ve published papers on probing static representations, and the results often seem intuitive and explanatory. However, the presence of a feature at the end of training is hardly informative about the inductive bias of a model on its own! Consider Lovering et al., who found that the ease of extracting a feature at the start of training, along with an analysis of the finetuning data, has deeper implications for finetuned performance than we get by simply probing at the end of training.\nLet us consider an explanation usually based on analyzing static models: hierarchical behavior in language models. An example of this approach is the claim that words that are closely linked on a syntax tree have representations that are closer together, compared to words that are syntactically farther. How can we know that the model is behaving hierarchically by grouping words according to syntactic proximity? Alternatively, syntactic neighbors may be more strongly linked due to a strong correlation between nearby words because they have higher joint frequency distributions. For example, perhaps constituents like “football match” are more …","date":165456e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":165456e4,"objectID":"1f4b7b7bc5f129bd99684def783b096a","permalink":"https://nsaphra.github.io/post/creationism/","publishdate":"2022-06-07T00:00:00Z","relpermalink":"/post/creationism/","section":"post","summary":"Nothing in Deep Learning Makes Sense Except in the Light of SGD.","tags":["training dynamics","rant"],"title":"Interpretability Creationism","type":"post"},{"authors":null,"categories":null,"content":"","date":1654093800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654093800,"objectID":"f8dc050841220ae760b6bf81c003d8c4","permalink":"https://nsaphra.github.io/talk/sources-of-variance-in-pretraining-and-finetuning-keynote/","publishdate":"2022-06-01T14:30:00Z","relpermalink":"/talk/sources-of-variance-in-pretraining-and-finetuning-keynote/","section":"event","summary":"","tags":[],"title":"Sources of Variance in Pretraining and Finetuning (Keynote)","type":"event"},{"authors":["Josef Valvoda","Naomi Saphra","Jonathan Rawski","Adina Williams","Ryan Cotterell"],"categories":null,"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654041600,"objectID":"93ba1051802275fe341bb27f716eef37","permalink":"https://nsaphra.github.io/publication/valvoda-benchmarking-2022/","publishdate":"2022-06-01T18:43:51.338959Z","relpermalink":"/publication/valvoda-benchmarking-2022/","section":"publication","summary":"Recombining known primitive concepts into larger novel combinations is a quintessentially human cognitive capability. Whether large neural models in NLP acquire this ability while learning from data is an open question. In this paper, we look at this problem from the perspective of formal languages. We use deterministic finite-state transducers to make an unbounded number of datasets with controllable properties governing compositionality. By randomly sampling over many transducers, we explore which of their properties (number of states, alphabet size, number of transitions etc.) contribute to learnability of a compositional relation by a neural network. In general, we find that the models either learn the relations completely or not at all. The key is transition coverage, setting a soft learnability limit at 400 examples per transition.","tags":null,"title":"Benchmarking Compositionality with Formal Languages","type":"publication"},{"authors":null,"categories":null,"content":"","date":1641049200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641049200,"objectID":"96db609fc9fb45c48250217cd1ffbb07","permalink":"https://nsaphra.github.io/talk/mathematical-fundamentals-of-ai/","publishdate":"2022-01-01T15:00:00Z","relpermalink":"/talk/mathematical-fundamentals-of-ai/","section":"event","summary":"","tags":[],"title":"Mathematical Fundamentals of AI","type":"event"},{"authors":[],"categories":[],"content":"Reaching the endpoint of a PhD studying how language models learn, I have spent several years telling people that I study “machine learning and natural language processing”. However, my colleagues who tried to understand or augment image classifiers would describe themselves only as working in “machine learning”. I argue that this pattern reflects thinking about what it means to be “application” work or “core” machine learning that damages our understanding of statistical modeling and deep learning as a whole.\nWhy do we know so little about how language models learn? This gap is in part because consideration of NLP as a domain is historically rare in venues that publish most training dynamics research, or analytic work in learning theory. A current search1 of ICML 2020 publications returned 169 papers with citations to “Association for Computational Linguistics” or “ACL”, even including citations to many potential sister conferences: NAACL, AACL, or EACL. A search for citations to a single vision conference, “Computer Vision and Pattern Recognition” or “CVPR”, turned up 541 papers. In COLT publications since 2017, the same searches turned up 13 and 23 papers, respectively. In ICML 2020, Wikitext-* or PTB references found only 16 results, while the most popular small corpus for image classification, MNIST, found 264 ICML publications2.\nLinguistics provides us with the salient concept of markedness (Andersen, 1989). In language, some forms of a word are the default form, while others are explicitly marked by some additional inflection. An example would be contrast between the word “marked”, which is an unmarked form compared to “unmarked”, which is marked by the prefix “un-”. In machine learning, we might call CV an unmarked domain by convention, in contrast to the marked NLP. This convention means that certain tasks and architectures are considered the default environments to understand. Such a convention privileges understanding continuous data over discrete; ConvNets over LSTMs; ResNets over Transformers; geometric tasks over structured prediction.\nUnderstanding one machine learning domain will always extend analysis of others. For example, latent tree structure is inherent to both domains, but in CV, it is obscured by the image data from which we must compose eyes and mouth into a face—and subsequently, body and face into a cow (Vedaldi et al., 2014). Image classification is also a language task, because it is our language that provides the intuitions which we use to construct ontologies that turn into image classes; English does not provide us with common distinctions for different packs of wolves, but it names every dog breed, and so the image labels are chosen according to available terminology.\nMany researchers think of text data as arcane, but the unmarked domain of CV displays many idiosyncrasies on which to overfit our understanding of statistical modeling. CV provides us with many interesting geometric phenomena, but the underlying structure of language without the added noisy channel of an image can provide a clear and simple domain worth analyzing, as well. A true understanding of statistical models must be a multi-domain understanding, not a mono-domain view focused on one task and its peculiarities.\nSearches were performed with Google Scholar. ↩︎\n*CL venues have also become distanced from work in computational linguistics (Reiter, 2007), leaving NLP as a field deprived of new scientific work in its data domain as well as new scientific work in its methodologies. ↩︎\n","date":1619568e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619568e3,"objectID":"54cd3c5e6877e481208ea7f438cf2afe","permalink":"https://nsaphra.github.io/post/monodomainism/","publishdate":"2021-04-28T00:00:00Z","relpermalink":"/post/monodomainism/","section":"post","summary":"A petty rant on the exceptional treatment of computer vision applications, directed at the machine learning community.","tags":[],"title":"Against Monodomainism","type":"post"},{"authors":["Jennifer C White","Tiago Pimentel","Naomi Saphra","Ryan Cotterell"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"3a038ff2f5a303efc525b357d35a991b","permalink":"https://nsaphra.github.io/publication/white-nonlinear-2021/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/white-nonlinear-2021/","section":"publication","summary":"Probes are models devised to investigate the encoding of knowledge{---}e.g. syntactic structure{---}in contextual representations. Probes are often designed for simplicity, which has led to restrictions on probe design that may not allow for the full exploitation of the structure of encoded information; one such restriction is linearity. We examine the case of a structural probe (Hewitt and Manning, 2019), which aims to investigate the encoding of syntactic structure in contextual representations through learning only linear transformations. By observing that the structural probe learns a metric, we are able to kernelize it and develop a novel non-linear variant with an identical number of parameters. We test on 6 languages and find that the radial-basis function (RBF) kernel, in conjunction with regularization, achieves a statistically significant improvement over the baseline in all languages{---}implying that at least part of the syntactic knowledge is encoded non-linearly. We conclude by discussing how the RBF kernel resembles BERT{'}s self-attention layers and speculate that this resemblance leads to the RBF-based probe{'}s stronger performance.","tags":null,"title":"A Non-Linear Structural Probe","type":"publication"},{"authors":["Thibault Sellam","Steve Yadlowsky","Jason Wei","Naomi Saphra","Alexander D'Amour","Tal Linzen","Jasmijn Bastings","Iulia Turc","Jacob Eisenstein","Dipanjan Das","Ian Tenney","Ellie Pavlick"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"bd7e97a3135b6b1e90d786d1772b2cb1","permalink":"https://nsaphra.github.io/publication/sellam-multiberts-2021/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/sellam-multiberts-2021/","section":"publication","summary":"Experiments with pre-trained models such as BERT are often based on a single checkpoint. While the conclusions drawn apply to the artifact tested in the experiment (i.e., the particular instance of the model), it is not always clear whether they hold for the more general procedure which includes the architecture, training data, initialization scheme, and loss function. Recent work has shown that repeating the pre-training process can lead to substantially different performance, suggesting that an alternative strategy is needed to make principled statements about procedures. To enable researchers to draw more robust conclusions, we introduce MultiBERTs, a set of 25 BERT-Base checkpoints, trained with similar hyper-parameters as the original BERT model but differing in random weight initialization and shuffling of training data. We also define the Multi-Bootstrap, a non-parametric bootstrap method for statistical inference designed for settings where there are multiple pre-trained models and limited test data. To illustrate our approach, we present a case study of gender bias in coreference resolution, in which the Multi-Bootstrap lets us measure effects that may not be detected with a single checkpoint. The models and statistical library are available online, along with an additional set of 140 intermediate checkpoints captured during pre-training to facilitate research on learning dynamics.","tags":null,"title":"The MultiBERTs: BERT Reproductions for Robustness Analysis","type":"publication"},{"authors":["Naomi Saphra"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672373752,"objectID":"b8f01fa263601e51d2f2b54e83c2be66","permalink":"https://nsaphra.github.io/publication/saphra-training-2021/","publishdate":"2022-12-30T04:15:52.145556Z","relpermalink":"/publication/saphra-training-2021/","section":"publication","summary":"","tags":[],"title":"Training dynamics of neural language models","type":"publication"},{"authors":null,"categories":null,"content":"","date":1597496400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597496400,"objectID":"7c2c2d15f067d5d112986821fb4a20cd","permalink":"https://nsaphra.github.io/talk/accessible-means-hackable-keynote/","publishdate":"2020-08-15T13:00:00Z","relpermalink":"/talk/accessible-means-hackable-keynote/","section":"event","summary":"In 2015, after over a decade of programming, I lost the ability to type. Confronted with a programmer’s worst nightmare, I began the slow process of learning to dictate code. While customizing my environment and relying on configurations and scripts from a wider voice coding community, I simultaneously was confronted with paternalistic attitudes towards disabled people, attached to a framing of accessibility as “accommodation”. Often, accommodations and products for disabled people have a rigid model for their use – but the needs of blind people are just as diverse as the needs of those with sight, and disabled people are perfectly capable of improving on the use model that you offer to them. This is a story and a call for accessible systems that are open and adaptable, that allow people like me the agency to improve the tools they use.","tags":[],"title":"Accessible Means Hackable (Keynote)","type":"event"},{"authors":["Mohammad Tahaei","Kami Vaniea","Naomi Saphra"],"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"abe80faa3b0410b858df31ecd6852d1d","permalink":"https://nsaphra.github.io/publication/tahaei-understanding-2020/","publishdate":"2020-05-25T18:43:51.334998Z","relpermalink":"/publication/tahaei-understanding-2020/","section":"publication","summary":"","tags":null,"title":"Understanding Privacy-Related Questions on Stack Overflow","type":"publication"},{"authors":["Naomi Saphra","Adam Lopez"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"c6ab6253e79f173da71dc61818bb0c0d","permalink":"https://nsaphra.github.io/publication/saphra-lstms-2020/","publishdate":"2020-10-14T12:08:57.271448Z","relpermalink":"/publication/saphra-lstms-2020/","section":"publication","summary":"Recent work in NLP shows that LSTM language models capture hierarchical structure in language data. In contrast to existing work, we consider the *learning* process that leads to their compositional behavior. For a closer look at how an LSTM's sequential representations are composed hierarchically, we present a related measure of Decompositional Interdependence (DI) between word meanings in an LSTM, based on their gate interactions. We connect this measure to syntax with experiments on English language data, where DI is higher on pairs of words with lower syntactic distance. To explore the inductive biases that cause these compositional representations to arise during training, we conduct simple experiments on synthetic data. These synthetic experiments support a specific hypothesis about how hierarchical structures are discovered over the course of training: that LSTM constituent representations are learned bottom-up, relying on effective representations of their shorter children, rather than learning the longer-range relations independently from children.","tags":null,"title":"LSTMs Compose (and Learn) Bottom-Up","type":"publication"},{"authors":["Tiago Pimentel","Naomi Saphra","Adina Williams","Ryan Cotterell"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"1f257a6af6cd97d406d445160bb2453c","permalink":"https://nsaphra.github.io/publication/pimentel-pareto-2020/","publishdate":"2020-10-14T12:08:57.272324Z","relpermalink":"/publication/pimentel-pareto-2020/","section":"publication","summary":"The question of how to probe contextual word representations in a way that is principled and useful has seen significant recent attention. In our contribution to this discussion, we argue, first, for a probe metric that reflects the trade-off between probe complexity and performance: the Pareto hypervolume. To measure complexity, we present a number of parametric and non-parametric metrics. Our experiments with such metrics show that probe's performance curves often fail to align with widely accepted rankings between language representations (with, e.g., non-contextual representations outperforming contextual ones). These results lead us to argue, second, that common simplistic probe tasks such as POS labeling and dependency arc labeling, are inadequate to evaluate the properties encoded in contextual word representations. We propose full dependency parsing as an example probe task, and demonstrate it with the Pareto hypervolume. In support of our arguments, the results of this illustrative experiment conform closer to accepted rankings among contextual word representations.","tags":null,"title":"Pareto Probing: Trading Off Accuracy for Complexity","type":"publication"},{"authors":[],"categories":[],"content":"In August of 2015, my hands stopped working. I could still control them, but every movement accumulated more pain, so every motion came with a cost: getting dressed in the morning, sending a text, lifting a glass. I was interning at Google that summer about to begin a PhD in Scotland, but coding all day would have left me in agony. In relating this story, I often mention that for months before I learned to work without my hands, I had nothing to do but go to a bar and order a shot of vodka with a straw in it. This is a very funny joke.\nI have been in pain for four years.\nTalon Due to this disability, I cannot type or write by hand. Many people have asked me about the stack that enables me to be productive in spite of this limitation. I hope this information is helpful both for people with more severe limitations, and for programmers with mild repetitive stress injuries who can benefit from reducing their keyboard use.\nThe star of the show is Talon, a system which makes it easy to write customized grammars and scripts that work with speech recognition systems to enable programming. Commands range from simple aliases for common symbols to complex meta-commands which repeat a previous utterance or change dictation modes. For example, just in the case of parentheses, I have separate commands for (, ), (), and ()⬅️ (which leaves the cursor between parentheses so my next utterance is bracketed).\nEach Talon user has a number of personal scripts. The most precious script that I’ve written is probably my indexed clipboard:\nfrom talon.voice import Key, press, Str, Context from talon import clip from .talon_community.utils import * ctx = Context(\u0026#39;clipboard\u0026#39;) def copy_selection(m): with clip.capture() as sel: press(\u0026#39;cmd-c\u0026#39;) if len(m._words) \u0026gt; 1: key = \u0026#39; \u0026#39;.join(parse_words(m)) value = sel.get() keymap[\u0026#39;paste %s\u0026#39; % key] = value ctx.keymap(keymap) ctx.reload() else: clip.set(sel.get()) keymap = { \u0026#39;paste\u0026#39;: Key(\u0026#39;cmd-v\u0026#39;), \u0026#39;clip [\u0026lt;dgndictation\u0026gt;]\u0026#39;: copy_selection, } ctx.keymap(keymap) The use is simple. After selecting a particular phrase using my cursor control commands, I say “clip [foo]”, and every time I want to enter the same phrase after, I say “paste [foo]”. I therefore only have to dictate a particularly obnoxious variable name once. However, it does introduce a new challenge: every variable has two names, its written name and its spoken name. This unfortunate side effect exacerbates the difficulty of naming variables, which has been called “the hardest problem in computer science”.\nIf you are a vim or Emacs power user, this may all feel familiar to you. I have commands for searching, moving a cursor, selection, and manipulating the clipboard. Learning to dictate code is a lot like learning a new text editor very thoroughly, down to the challenge of customizing for your particular languages and needs.\nThe Talon community has specialized commands that take effect depending on application or programming language. For a Perl user, for example, a good starting point might be to borrow settings from Emily Shea:\nMy Talon setup relies on Dragon for the speech recognition side. Unfortunately, Nuance has discontinued OSX Dragon editions that make scripting possible. The coder behind Talon, Ryan Hileman, is working on a suitable replacement but at time of writing, it is not yet ready.\nInterlude People often ask for my diagnosis, but it officially depends on the country I’m in. After an initial assumption that carpal tunnel was to blame, a rheumatologist gave me my first American diagnosis: fibromyalgia, a word which is Doctorspeak for “go away”.\nI did not go away. A neurologist performed a skin biopsy that led to my official American diagnosis of “idiopathic small fiber neuropathy”, meaning that I am missing crucial nerve fibers that transmit heat and pain but nobody knows why. Idiopathic is also Doctorspeak for “go away”.\nI went away to the UK. I brought my medical records from America, but my British neurologist did not read my records or perform examinations. After a brief conversation, he gave me my British diagnosis by submitting a note that he had no evidence of any physical cause, and he “suspected significant functional overlay”, which is how they teach you to call someone delusional in medical school.\nMy GP read the note and informed me: He would not prescribe me painkillers. He would not send me for a second opinion from a neurologist, or treatment from any other specialist. The only referral he would write would be to a psychologist to help me “resolve the underlying issues behind my pain”.\nHe then kicked me out of his office for using the word “fucking”. “We do not tolerate cursing”, said a sign in the lobby.\nEquipment For dictating, I use two different microphones. In the office, I use a Sennheiser ME-3, while for travel I use a Bluetooth headset, the Sennheiser MB Pro 2.\nAnother essential piece of equipment for me is my foot pedal, a PageFlip Firefly. It is programmable, so I have modified the settings to include …","date":1565284302,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565284302,"objectID":"ba4c158a6dcdc097466590cb4685e922","permalink":"https://nsaphra.github.io/post/hands/","publishdate":"2019-08-08T18:11:42+01:00","relpermalink":"/post/hands/","section":"post","summary":"In August of 2015, my hands stopped working. This is what happened next.","tags":["personal"],"title":"What Does a Coder Do If They Can't Type?","type":"post"},{"authors":null,"categories":null,"content":"","date":1564059600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564059600,"objectID":"a090188f0dc7e7608ad4e355a705ef28","permalink":"https://nsaphra.github.io/talk/blackbox-nlp-panel-discussion/","publishdate":"2019-07-25T13:00:00Z","relpermalink":"/talk/blackbox-nlp-panel-discussion/","section":"event","summary":"","tags":[],"title":"Blackbox NLP Panel Discussion","type":"event"},{"authors":null,"categories":null,"content":"","date":1559048400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559048400,"objectID":"61ac022b8ef13f4ac4f4876f051011f7","permalink":"https://nsaphra.github.io/talk/get-hooked-on-neural-net-inspection-that-was-a-pun/","publishdate":"2019-05-28T13:00:00Z","relpermalink":"/talk/get-hooked-on-neural-net-inspection-that-was-a-pun/","section":"event","summary":"","tags":[],"title":"Get Hooked On Neural Net Inspection! That was a pun!","type":"event"},{"authors":null,"categories":null,"content":"","date":1559048400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559048400,"objectID":"3c42f8e8fd51c8c98609e21b80f5e939","permalink":"https://nsaphra.github.io/talk/learning-dynamics-of-lstms/","publishdate":"2019-05-28T13:00:00Z","relpermalink":"/talk/learning-dynamics-of-lstms/","section":"event","summary":"","tags":[],"title":"Learning Dynamics of LSTMs","type":"event"},{"authors":null,"categories":null,"content":"","date":1559048400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559048400,"objectID":"8a9d183470ca175bb856bff1452a56a3","permalink":"https://nsaphra.github.io/talk/learning-dynamics-of-text-models/","publishdate":"2019-05-28T13:00:00Z","relpermalink":"/talk/learning-dynamics-of-text-models/","section":"event","summary":"","tags":[],"title":"Learning Dynamics of Text Models","type":"event"},{"authors":null,"categories":null,"content":"","date":1559048400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559048400,"objectID":"722a591668d08c4ef4d5bf097b4e1383","permalink":"https://nsaphra.github.io/talk/transparent-hackable-accessible/","publishdate":"2019-05-28T13:00:00Z","relpermalink":"/talk/transparent-hackable-accessible/","section":"event","summary":"","tags":[],"title":"Transparent, Hackable, Accessible","type":"event"},{"authors":null,"categories":null,"content":"","date":1551186e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551186e3,"objectID":"c3f25095e9b0d3f43c178d21365e0950","permalink":"https://nsaphra.github.io/talk/paying-the-panopticon/","publishdate":"2019-02-26T13:00:00Z","relpermalink":"/talk/paying-the-panopticon/","section":"event","summary":"A standup comedy set about machine learning funding.","tags":[],"title":"Paying the Panopticon","type":"event"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://nsaphra.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Naomi Saphra","Adam Lopez"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"e0658631ff11700a67354697390c93e8","permalink":"https://nsaphra.github.io/publication/saphra-sparsity-2019/","publishdate":"2019-07-25T18:43:51.344759Z","relpermalink":"/publication/saphra-sparsity-2019/","section":"publication","summary":"Concerns about interpretability, computational resources, and principled inductive priors have motivated efforts to engineer sparse  neural  models for NLP tasks. If sparsity is important for NLP, might well-trained neural models naturally become roughly sparse? Using the Taxi-Euclidean norm to measure sparsity, we find that frequent input words are associated with concentrated or sparse activations, while frequent target words are associated with dispersed activations but concentrated gradients. We find that  gradients associated with function words are more concentrated than the gradients of content words, even controlling for word frequency.","tags":null,"title":"Sparsity Emerges Naturally in Neural Language Models","type":"publication"},{"authors":["Naomi Saphra","Adam Lopez"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6fb4da02350dbafeffe1e353ccae270e","permalink":"https://nsaphra.github.io/publication/saphra-understanding-2019/","publishdate":"2019-07-25T18:43:51.344052Z","relpermalink":"/publication/saphra-understanding-2019/","section":"publication","summary":"Research has shown that neural models implicitly encode linguistic features, but there has been no research showing *how* these encodings arise as the models are trained. We present the first study on the learning dynamics of neural language models, using a simple and flexible analysis method called Singular Vector Canonical Correlation Analysis (SVCCA), which enables us to compare learned representations across time and across models, without the need to evaluate directly on annotated data. We probe the evolution of syntactic, semantic, and topic representations and find that part-of-speech is learned earlier than topic; that recurrent layers become more similar to those of a tagger during training; and embedding layers less similar. Our results and methods could inform better learning algorithms for NLP models, possibly to incorporate linguistic information more effectively.","tags":["Computer Science - Computation and Language","Computer Science - Neural and Evolutionary Computing"],"title":"Understanding Learning Dynamics Of Language Models with SVCCA","type":"publication"},{"authors":[],"categories":[],"content":" Models can be built incrementally by modifying their hyperparameters during training. This is most common in transfer learning settings, in which we seek to adapt the knowledge in an existing model for a new domain or task. The more general problem of continuous learning is also an obvious application. Even with a predefined data set, however, incrementally constraining the topology of the network can offer benefits as regularization.\nDynamic Hyperparameters The easiest incrementally modified models to train may be those in which hyperparameters are updated at each epoch. In this case, we do not mean those hyperparameters associated with network topology, such as the number or dimension of layers. There are many opportunities to adjust the topology during training, but the model often requires heavy retraining in order to impose reasonable structure again, as demonstrated clearly in the case of memory networks1. If we instead focus on the weights associated with regularizers and gates, we can gradually learn structure without frequent retraining to accommodate radically altered topologies.\nCurriculum Dropout Hinton et al.2 describes dropout as reducing overfitting by preventing co-adaptation of feature detectors which happened to perfectly fit the data. In this interpretation, co-adaptive clusters of neurons are concurrently activated. Randomly suppressing these neurons forces them to develop independence.\nIn standard dropout, these co-adaptive neurons are treated as equally problematic at all stages of training. However, Morerio et. al.3 posit that early in training, co-adaptation may represent the beginnings of an optimal self organization of the network. In this view, these structures mainly pose the threat of overfitting later in training. The authors therefore introduce a hyperparameter schedule for the dropout ratio, increasing the rate of dropout as training continues. To the best of my knowledge, this is the only proposal of adaptive regularization published.\nMollifying Networks Mollifying networks4 are, to my knowledge, the only existing attempt to combine techniques focused on incrementally manipulating the distribution of data with techniques focused on incrementally manipulating the representational capacity of the model. Mollifying networks incrementally lower the temperature of the data through simulated annealing while simultaneously modifying various hyperparameters to permit longer-range dependencies. In the case of an LSTM, they set the output gate to 1, input gate to \\(\\frac{1}{t}\\), and forget gate to \\(1 - \\frac{1}{t}\\), where \\(t\\) is the annealing time step. Using this system, the LSTM initially behaves as a bag-of-words model, gradually adding the capacity to handle more context at each time step.\nMollifying networks use a different data schedule for each layer, annealing the noise in lower layers faster than in higher layers because lower-level representations are assumed to learn faster.\nAdaptive Architectures The hyperparameters most difficult to modify during training may be those which dictate the topology of the model architecture itself. Nonetheless, the deep learning literature contains a long history of techniques which adapt the model architecture during training, often in response to the parameters being learned. Methods like these can help search optimally by smoothing functions at the beginning of training, speed up learning by starting with a simpler model, or compress a model to fit easily on a phone or embedded device. Most of these methods could be classified as either growing a model by adding parameters mid-training or shrinking a model by pruning edges or nodes.\nArchitecture Growth Some recent transfer learning strategies have relied on growing architectures by creating entire new modules focused on the new task with connections to the existing network56. If the goal is to instead augment an existing network by adding a small number of parameters, the problem bears a resemblance to traditional nonparametric learning, because we need not explicitly limit the model space to begin with.\nClassical techniques in neural networks such as Cascade Correlation Networks7 and Dynamic Node Creation8 added new nodes at random one by one and trained them individually. On modern large-scale architectures and problems, this is intractable. Furthermore, the main advantage of such methods is that they approach a minimal model, which is an aim that modern deep learning practitioners no longer consider valuable thanks to leaps in computing power in the decades since. Modern techniques for incrementally growing networks must make 2 decisions: 1) When (and where) do we add new parameters? 2) How do we train new parameters?\nWarde-Farley et. al.9 add parameters in bulk after training an entire network. The augmentation takes the form of specialized auxiliary layers added to the existing network in parallel. These layers are trained on class boundaries that the original generalist model …","date":1534171742,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534171742,"objectID":"cabf39142a0b6cf8d80f9ee2f0a063a1","permalink":"https://nsaphra.github.io/post/model-scheduling/","publishdate":"2018-08-13T15:49:02+01:00","relpermalink":"/post/model-scheduling/","section":"post","summary":"Notes on incrementally constraining the topology of a neural network as a method of regularization.","tags":[],"title":"Model Scheduling","type":"post"},{"authors":["Naomi Saphra","Adam Lopez"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"a0dae325b02d3a98c1f85871cf72283f","permalink":"https://nsaphra.github.io/publication/saphra-evaluating-2016/","publishdate":"2019-07-25T18:43:51.342258Z","relpermalink":"/publication/saphra-evaluating-2016/","section":"publication","summary":"","tags":null,"title":"Evaluating Informal-Domain Word Representations With UrbanDictionary","type":"publication"},{"authors":["Naomi Saphra","Adam Lopez"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"dd0a8aeefcde737848b27c1bcd4dc20b","permalink":"https://nsaphra.github.io/publication/naomi-saphra-amrica-2015/","publishdate":"2019-07-25T18:43:51.341368Z","relpermalink":"/publication/naomi-saphra-amrica-2015/","section":"publication","summary":"Abstract Meaning Representation (AMR), an annotation scheme for natural language semantics, has drawn attention for its simplicity and representational power. Because AMR annotations are not designed for human readability, we present AMRICA, a visual aid for exploration of AMR annotations. AMRICA can visualize an AMR or the difference between two AMRs to help users diagnose interannotator disagreement or errors from an AMR parser. AMRICA can also automatically align and visualize the AMRs of a sentence and its translation in a parallel text. We believe AMRICA will simplify and streamline exploratory research on cross-lingual AMR corpora.","tags":null,"title":"AMRICA: an AMR Inspector for Cross-language Alignments","type":"publication"},{"authors":["Nathan Schneider","Brendan O'Connor","Naomi Saphra","David Bamman","Manaal Faruqui","Noah A. Smith","Chris Dyer","Jason Baldridge"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"3ba387eeaae398cafd6eb3138fe9a052","permalink":"https://nsaphra.github.io/publication/schneider-framework-2014/","publishdate":"2019-07-25T18:43:51.3374Z","relpermalink":"/publication/schneider-framework-2014/","section":"publication","summary":"","tags":null,"title":"A framework for (under) specifying dependency syntax without overloading annotators","type":"publication"},{"authors":["Ryan Cotterell","Adithya Renduchintala","Naomi Saphra","Chris Callison-Burch"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"55c82ee663eef10711bd27bffa37d775","permalink":"https://nsaphra.github.io/publication/cotterell-algerian-2014/","publishdate":"2019-07-25T18:43:51.338959Z","relpermalink":"/publication/cotterell-algerian-2014/","section":"publication","summary":"Arabic is not just one language, but rather a collection of dialects in addition to Modern Standard Arabic (MSA). While MSA is used in formal situations, dialects are the language of every day life. Until recently, there was very little dialectal Arabic in written form. With the advent of social-media, however, the landscape has changed. We provide the first romanized code-switched Algerian Arabic-French corpus annotated for word-level language id. We review the history and sociological factors that make the linguistic situation in Algerian unique and highlight the value of this corpus to the natural language processing and linguistics communities. To build this corpus, we crawled an Algerian newspaper and extracted the comments from the news story. We discuss the informal nature of the language in the corpus and the challenges it will present. Additionally, we provide a preliminary analysis of the corpus. We then discuss some potential uses of our corpus of interest to the computational linguistics community.","tags":null,"title":"An Algerian Arabic-French Code-Switched Corpus","type":"publication"},{"authors":["A. Vedaldi","S. Mahendran","S. Tsogkas","S. Maji","B. Girshick","J. Kannala","E. Rahtu","I. Kokkinos","M. B. Blaschko","D. Weiss","B. Taskar","K. Simonyan","Naomi Saphra","S. Mohamed"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"79a703fba91beca02e44102ac3e756a9","permalink":"https://nsaphra.github.io/publication/vedaldi-understanding-2014/","publishdate":"2019-07-25T18:43:51.334998Z","relpermalink":"/publication/vedaldi-understanding-2014/","section":"publication","summary":"","tags":null,"title":"Understanding Objects in Detail with Fine-grained Attributes","type":"publication"},{"authors":[],"categories":[],"content":"[Note - This is a repost of a post I made on my old blog while I was in undergrad. I’m including it in case someone finds it useful, since my old blog is defunct. I haven’t significantly edited it, so I’m sorry if it doesn’t fit into my current style.]\nThis post is directed to a lay CS audience. I am an undergraduate in CS, so I consider myself part of that audience. If you’re awesome at machine learning already and don’t want to help me along here, just read the paper.\nLatent Dirichlet Allocation (LDA) is a common method of topic modeling. That is, if I have a document and want to figure out if it’s a sports article or a mathematics paper, I can use LDA to build a system that looks at other sports articles or mathematics papers and automatically decides whether this unseen document’s topic is sports or math.\nTo LDA, a document is just a collection of topics where each topic has some particular probability of generating a particular word. For our potential sports article, the word “average” appears 4 times. What’s the probability of a sports topic generating that many instances of “average”? We determine this by looking at each training document as a “bag of words” pulled from a distribution selected by a Dirichlet process.\nDirichlet is a distribution specified by a vector parameter $$\\alpha$$ containing some \\(\\alpha_i\\) corresponding to each topic \\(i\\), which we write as \\(\\textrm{Dir}(\\alpha)\\). The formula for computing the probability density function for each topic vector \\(x\\) is proportional to the product over all topics \\(i\\) of \\(x_i \\alpha_i\\). \\(x_i\\) is the probability that the topic is \\(i\\), so the items in \\(x\\) must sum to 1. That keeps you from getting arbitrarily large probabilities by giving arbitrarily large values of \\(x\\).\nConfused? Ready for a picture ripped off Wikipedia?\nThose graphs all show Dirichlet distributions for three topics. That triangle at the bottom has one side for each topic, and the closer a point on the triangle is to side \\(i\\) the higher the probability of topic \\(i\\). The purple curve is the probability density function over the mixture of topics. See how the edges of the triangle all have probability 0? We said that the pdf is proportional to \\(x_i \\alpha_i\\), so if \\(x_i\\) is 0, the probability of that mixture of topics is 0. That restricts our model a bit and ensures that we never are totally certain about the topic of a document.\nOkay, we’ve got “Dirichlet”, so let’s pop back up to the concept of LDA. If we want to find that mixture of topics for a document, we first need to determine the value of each \\(x_i\\). That means we’ve got another Dirichlet distribution in our model for each topic i where instead of the sides of the triangle being topics, they’re words. Picture the topic “sports article” like those distributions above, but instead of sitting on triangles they’re on shapes with so many sides the shapes go into as many dimensions as we have topics.. If “average” appears in a sports article, the bump pushes closer to the side for “average”.\nThe Latent part of LDA comes into play because in statistics, a variable we have to infer rather than directly observing is called a “latent variable”. We’re only directly observing the words and not the topics, so the topics themselves are latent variables (along with the distributions themselves).\nLDA assumes that each document k is generated by:\nFrom our Dirichlet distribution for k, sample a random distribution of topics. That is, pick a place on that triangle that is associated with a certain probability of generating each topic. If we choose a place very close to the “sports article” edge, we have a higher probability of picking “sports article”. The probability of picking a particular place on the triangle is described by the pdf of the Dirichlet distribution (the placement of the purple mound). For each topic, pick a distribution of words for that topic from the Dirichlet for that topic. For each word in document \\(k\\), From the distribution of topics selected for \\(k\\), sample a topic, like “sports article”. From the distribution selected for “sports article”, pick the current word. So let’s say your first four words all come from baseball and your document maybe starts off “average the bat bat”. If that’s not how you tend to write, that’s okay. All models are wrong.\nThe important thing to understand is that your Dirichlet priors are distribution of distributions, which are selected to generate each word.\nWe’re generally not just making these distributions for the heck of it or to actually generate documents. We want to figure out what topic was probably used for each word by our lazy writer who randomly generates each word. Maybe it’s been a while since you took probability, but do you remember this guy? \\[ P(A|B) = \\frac{P(B|A) P(A)}{P(B)} \\]\nThis is Bayes’ Theorem. We already know the probability of generating a particular word given a topic according to our model. That’s the probability of sampling …","date":1341792e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1341792e3,"objectID":"d2d78946109f7933bf8e431faf1e7526","permalink":"https://nsaphra.github.io/post/lda/","publishdate":"2012-07-09T00:00:00Z","relpermalink":"/post/lda/","section":"post","summary":"An explanation of Latent Dirichlet Allocation (LDA), a common method of topic modeling.","tags":[],"title":"Understanding Latent Dirichlet Allocation","type":"post"},{"authors":["Matthew Blaschko","Ross B. Girshick","Juho Kannala","Iasonas Kokkinos","Siddarth Mahendran","Subhransu Maji","Sammy Mohamed","Esa Rahtu","Naomi Saphra","Karen Simonyan"],"categories":[],"content":"","date":1325376e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672373751,"objectID":"e9f2da9427975cfbcf979d7852fc5c63","permalink":"https://nsaphra.github.io/publication/blaschko-towards-2012/","publishdate":"2022-12-30T04:15:51.618849Z","relpermalink":"/publication/blaschko-towards-2012/","section":"publication","summary":"","tags":[],"title":"Towards a detailed understanding of objects and scenes in natural images","type":"publication"}]